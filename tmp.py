

    def _run_prediction(self) -> Dict[str, Any]:
        """è¿è¡Œé¢„æµ‹ï¼ˆä¸“é—¨ç”¨äºKaggleæäº¤ï¼‰"""
        logger.info("ğŸ”® Running prediction for Kaggle submission...")

        # åŠ è½½æœ€ä½³æ¨¡å‹
        checkpoint_path = self.config.get("checkpoint_path")
        if not checkpoint_path:
            # è‡ªåŠ¨æŸ¥æ‰¾æœ€ä½³æ£€æŸ¥ç‚¹
            exp_dir = Path(self.config.outputs.experiment_dir)
            checkpoint_dir = exp_dir / "checkpoints"

            # æŸ¥æ‰¾æœ€ä½³F1æ£€æŸ¥ç‚¹
            best_checkpoints = list(checkpoint_dir.glob("best-epoch=*-val_f1=*.ckpt"))
            if best_checkpoints:
                checkpoint_path = str(sorted(best_checkpoints)[-1])  # å–æœ€æ–°çš„
            else:
                raise FileNotFoundError("No trained model found. Please run training first.")

        logger.info(f"ğŸ“¥ Loading model from: {checkpoint_path}")

        # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹ï¼ˆæ­£ç¡®æ–¹å¼ï¼‰
        from lightning_landslide.src.models.classification_module import LandslideClassificationModule

        model = LandslideClassificationModule.load_from_checkpoint(checkpoint_path)
        model.eval()

        # å®ä¾‹åŒ–æ•°æ®æ¨¡å—å’Œè®­ç»ƒå™¨
        datamodule = instantiate_from_config(self.config.data)
        trainer = instantiate_from_config(self.config.trainer)

        # è®¾ç½®æ•°æ®ï¼ˆåªéœ€è¦æµ‹è¯•é›†ï¼‰
        datamodule.setup("predict")

        # è¿›è¡Œé¢„æµ‹ï¼ˆä¸è®¡ç®—ä»»ä½•æŒ‡æ ‡ï¼‰
        predictions = trainer.predict(model, datamodule.predict_dataloader())

        # å¤„ç†é¢„æµ‹ç»“æœ
        all_probs = []
        all_preds = []

        for batch_preds in predictions:
            probs = batch_preds["probabilities"].cpu().numpy()
            preds = batch_preds["predictions"].cpu().numpy()
            all_probs.extend(probs)
            all_preds.extend(preds)

        # è·å–æµ‹è¯•æ ·æœ¬ID
        test_dataset = datamodule.test_dataset
        sample_ids = [test_dataset.data_index.iloc[i]["ID"] for i in range(len(test_dataset))]

        # åˆ›å»ºæäº¤æ–‡ä»¶
        submission_df = pd.DataFrame(
            {"ID": sample_ids, "label": [int(pred) for pred in all_preds]}  # Kaggleé€šå¸¸è¦æ±‚æ•´æ•°æ ‡ç­¾
        )

        # ä¿å­˜æäº¤æ–‡ä»¶
        exp_dir = Path(self.config.outputs.experiment_dir)
        submission_path = exp_dir / "kaggle_submission.csv"
        submission_df.to_csv(submission_path, index=False)

        # ä¿å­˜è¯¦ç»†é¢„æµ‹ç»“æœï¼ˆåŒ…å«æ¦‚ç‡ï¼‰
        detailed_results = pd.DataFrame({"ID": sample_ids, "probability": all_probs, "prediction": all_preds})

        detailed_path = exp_dir / "detailed_predictions.csv"
        detailed_results.to_csv(detailed_path, index=False)

        logger.info(f"âœ… Prediction completed!")
        logger.info(f"ğŸ“„ Kaggle submission saved to: {submission_path}")
        logger.info(f"ğŸ“Š Detailed results saved to: {detailed_path}")
        logger.info(f"ğŸ¯ Predicted {len(sample_ids)} samples")

        # é¢„æµ‹ç»Ÿè®¡
        positive_ratio = sum(all_preds) / len(all_preds)
        logger.info(f"ğŸ“ˆ Positive prediction ratio: {positive_ratio:.3f}")

        return {
            "submission_path": str(submission_path),
            "detailed_path": str(detailed_path),
            "num_predictions": len(sample_ids),
            "positive_ratio": positive_ratio,
            "checkpoint_used": checkpoint_path,
        }
