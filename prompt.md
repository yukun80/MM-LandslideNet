## 角色
你是一个资深的计算机视觉和深度学习算法工程师，始终遵循第一性原理和奥卡姆剃刀原则。

## 背景
当前正在一场面向多模态遥感图像滑坡场景分类竞赛。当前代码库模型构建是已有的尝试，但存在一些问题。
当前我的模型构建在lightning_landslide/src/models/optical_swin.py。为了兼容光学波段和其他波段，数据集类在lightning_landslide/src/data/multimodal_dataset.py。配置文件分散在lightning_landslide/configs路径下。


## 任务1
现在，我发现了一个使用pytorch lightning的深度学习项目，地址为：https://github.com/CompVis/latent-diffusion。这个代码库在训练的时候可以自动保存每一次训练时候的配置和权重以及结果，并且有着良好的扩展性，可以通过配置文件和算法框架设计方便的添加不同模型以及训练配置，实现高效的多方法验证。这对于 kaggle 类竞赛需要构建不同的模型结构以及训练配置的测试至关重要。请你对latent-diffusion 代码库进行充分的研究，理解这个框架是如何实现的。

## 任务2
我想在lightning_landslide路径下模仿latent-diffusion代码库中的算法框架，构建一个可扩展的多模态分类框架来开展这个竞赛任务。通过配置文件设置来构建不同的模型结构和训练配置，并且兼容legacy/optical_src中的光学通道分类模型。因此当前代码和类的名字都是multimodal，而不是optical，这是因为我想通过配置文件设置使用数据的波段组合，这样也兼容纯光学波段数据。当前我已经下载了预训练权重到pretrained路径。

请你分析当前 lightning_landslide 框架要成功执行swin 模型训练、测试、预测Pipline还需要如何完善代码？请给出详细的代码修改建议。


## 任务1
首先请你对legacy/optical_src路径下的算法框架进行充分的研究，理解当前使用swin和光学波段数据构建的分类模型。当前optical_src中我使用了pytorch构建算法。然而，我发现使用pytorch需要花大量精力维护训练和测试等大量工程代码。因此，我决定使用pytorch lightning和yaml配置文件构建一个可扩展的框架。