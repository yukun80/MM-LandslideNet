# =============================================================================
# lightning_landslide/src/data/kfold_datamodule.py - KæŠ˜äº¤å‰éªŒè¯æ•°æ®æ¨¡å—
# =============================================================================

"""
KæŠ˜äº¤å‰éªŒè¯æ•°æ®æ¨¡å— - ä¸“ä¸ºKaggleç«èµ›è®¾è®¡

è¿™ä¸ªæ¨¡å—å®ç°äº†ç«èµ›çº§çš„KæŠ˜äº¤å‰éªŒè¯ç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼š
1. åˆ†å±‚KæŠ˜åˆ†å‰²ç¡®ä¿æ¯æŠ˜ç±»åˆ«åˆ†å¸ƒä¸€è‡´
2. OOF(Out-of-Fold)é¢„æµ‹ç®¡ç†
3. æµ‹è¯•é›†é¢„æµ‹ä¸€è‡´æ€§å¤„ç†
4. ç§å­ç®¡ç†ç¡®ä¿å¯é‡ç°æ€§
"""

import pytorch_lightning as pl
from torch.utils.data import DataLoader, Subset
from sklearn.model_selection import StratifiedKFold, KFold
from typing import Optional, Dict, Any, List, Callable, Tuple
import logging
from pathlib import Path
import torch
import numpy as np
import pandas as pd
import json
from copy import deepcopy

from .multimodal_dataset import create_train_dataset, create_test_dataset
from .base import BaseDataModule

logger = logging.getLogger(__name__)


class KFoldDataModule(pl.LightningDataModule):
    """
    KæŠ˜äº¤å‰éªŒè¯æ•°æ®æ¨¡å—

    è®¾è®¡ç†å¿µï¼š
    1. ç«èµ›å¯¼å‘ï¼šä¸“é—¨ä¸ºKaggleç«èµ›è®¾è®¡çš„KæŠ˜éªŒè¯
    2. æ€§èƒ½ä¼˜å…ˆï¼šç¡®ä¿æ¯æŠ˜çš„æ•°æ®åˆ†å¸ƒå’Œæ¨¡å‹æ€§èƒ½
    3. å¯é‡ç°æ€§ï¼šä¸¥æ ¼çš„ç§å­ç®¡ç†å’ŒçŠ¶æ€ä¿å­˜
    4. é›†æˆå‹å¥½ï¼šä¸ºæ¨¡å‹é›†æˆå’Œå †å æä¾›æ”¯æŒ
    """

    def __init__(
        self,
        # åŸºç¡€æ•°æ®é…ç½®
        train_data_dir: str,
        test_data_dir: str,
        train_csv: str,
        test_csv: str,
        exclude_ids_file: Optional[str] = None,
        # KæŠ˜é…ç½®
        n_splits: int = 5,
        current_fold: int = 0,
        stratified: bool = True,
        # é€šé“é…ç½®
        channel_config: Dict[str, Any] = None,
        active_mode: str = "optical_only",
        # æ•°æ®åŠ è½½é…ç½®
        batch_size: int = 32,
        num_workers: int = 8,
        pin_memory: bool = True,
        shuffle_train: bool = True,
        # é¢„å¤„ç†é…ç½®
        preprocessing: Optional[Dict] = None,
        augmentation: Optional[Dict] = None,
        # KæŠ˜ç®¡ç†é…ç½®
        save_fold_info: bool = True,
        fold_info_dir: str = "outputs/kfold_info",
        # å…¶ä»–é…ç½®
        seed: int = 3407,
        **kwargs,
    ):
        """
        åˆå§‹åŒ–KæŠ˜æ•°æ®æ¨¡å—

        Args:
            n_splits: KæŠ˜æ•°é‡
            current_fold: å½“å‰è®­ç»ƒçš„æŠ˜æ•°(0-based)
            stratified: æ˜¯å¦ä½¿ç”¨åˆ†å±‚é‡‡æ ·
            save_fold_info: æ˜¯å¦ä¿å­˜æŠ˜ä¿¡æ¯
            fold_info_dir: æŠ˜ä¿¡æ¯ä¿å­˜ç›®å½•
        """
        super().__init__()

        # ä¿å­˜è¶…å‚æ•°
        self.save_hyperparameters()

        # åŸºç¡€é…ç½®
        self.train_data_dir = Path(train_data_dir)
        self.test_data_dir = Path(test_data_dir)
        self.train_csv = Path(train_csv)
        self.test_csv = Path(test_csv)
        self.exclude_ids_file = exclude_ids_file

        # KæŠ˜é…ç½®
        self.n_splits = n_splits
        self.current_fold = current_fold
        self.stratified = stratified

        # æ•°æ®é…ç½®
        self.channel_config = channel_config
        self.active_mode = active_mode
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.pin_memory = pin_memory
        self.shuffle_train = shuffle_train

        # é¢„å¤„ç†é…ç½®
        self.preprocessing = preprocessing or {}
        self.augmentation = augmentation or {}

        # KæŠ˜ç®¡ç†
        self.save_fold_info = save_fold_info
        self.fold_info_dir = Path(fold_info_dir)
        self.fold_info_dir.mkdir(parents=True, exist_ok=True)

        # ç§å­ç®¡ç†
        self.seed = seed

        # æ•°æ®é›†å’ŒæŠ˜ä¿¡æ¯
        self.full_dataset = None
        self.train_dataset = None
        self.val_dataset = None
        self.test_dataset = None
        self.fold_indices = None

        logger.info(f"ğŸ¯ KFoldDataModule initialized for {n_splits}-fold CV")
        logger.info(f"Current fold: {current_fold}/{n_splits-1}")
        logger.info(f"Stratified: {stratified}")

    def prepare_data(self) -> None:
        """å‡†å¤‡æ•°æ®å’ŒKæŠ˜åˆ†å‰²"""
        # éªŒè¯æ•°æ®æ–‡ä»¶å­˜åœ¨
        assert self.train_data_dir.exists(), f"Training data directory not found: {self.train_data_dir}"
        assert self.test_data_dir.exists(), f"Test data directory not found: {self.test_data_dir}"
        assert self.train_csv.exists(), f"Training CSV not found: {self.train_csv}"
        assert self.test_csv.exists(), f"Test CSV not found: {self.test_csv}"

        logger.info("âœ“ Data files validation passed")

    def setup(self, stage: Optional[str] = None) -> None:
        """è®¾ç½®KæŠ˜æ•°æ®é›†"""
        if stage == "fit" or stage is None:
            # åˆ›å»ºå®Œæ•´çš„è®­ç»ƒæ•°æ®é›†
            self.full_dataset = create_train_dataset(
                data_dir=str(self.train_data_dir),
                csv_file=str(self.train_csv),
                exclude_ids_file=self.exclude_ids_file,
                transform=None,  # åŸºç¡€å˜æ¢ï¼Œåç»­åœ¨DataLoaderä¸­å¤„ç†
                channel_config=self.channel_config,
                usage_mode=self.active_mode,
            )

            # ç”Ÿæˆæˆ–åŠ è½½KæŠ˜åˆ†å‰²
            self.fold_indices = self._generate_kfold_splits()

            # è·å–å½“å‰æŠ˜çš„æ•°æ®
            train_indices, val_indices = self.fold_indices[self.current_fold]

            # åˆ›å»ºå½“å‰æŠ˜çš„æ•°æ®é›†
            self.train_dataset = Subset(self.full_dataset, train_indices)
            self.val_dataset = Subset(self.full_dataset, val_indices)

            logger.info(f"Fold {self.current_fold}: Train={len(train_indices)}, Val={len(val_indices)}")

            # ä¿å­˜å½“å‰æŠ˜ä¿¡æ¯
            if self.save_fold_info:
                self._save_current_fold_info(train_indices, val_indices)

        if stage == "test" or stage is None:
            # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
            self.test_dataset = create_test_dataset(
                data_dir=str(self.test_data_dir),
                csv_file=str(self.test_csv),
                transform=self._create_transforms("test"),
                channel_config=self.channel_config,
                usage_mode=self.active_mode,
            )
            logger.info(f"Test dataset: {len(self.test_dataset)} samples")

    def _generate_kfold_splits(self) -> List[Tuple[np.ndarray, np.ndarray]]:
        """
        ç”ŸæˆKæŠ˜åˆ†å‰²ç´¢å¼•

        Returns:
            List of (train_indices, val_indices) for each fold
        """
        fold_file = self.fold_info_dir / f"{self.n_splits}fold_splits.json"

        # å°è¯•åŠ è½½å·²å­˜åœ¨çš„åˆ†å‰²
        if fold_file.exists():
            logger.info(f"Loading existing K-fold splits from {fold_file}")
            with open(fold_file, "r") as f:
                fold_data = json.load(f)
                return [(np.array(fold["train"]), np.array(fold["val"])) for fold in fold_data["folds"]]

        # ç”Ÿæˆæ–°çš„åˆ†å‰²
        logger.info(f"Generating new {self.n_splits}-fold splits...")

        # è·å–æ ‡ç­¾ç”¨äºåˆ†å±‚é‡‡æ ·
        labels = []
        for i in range(len(self.full_dataset)):
            _, label = self.full_dataset[i]
            labels.append(label)
        labels = np.array(labels)

        # åˆ›å»ºKæŠ˜åˆ†å‰²å™¨
        if self.stratified:
            kfold = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)
            splits = list(kfold.split(np.arange(len(labels)), labels))
        else:
            kfold = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)
            splits = list(kfold.split(np.arange(len(labels))))

        # ä¿å­˜åˆ†å‰²ä¿¡æ¯
        if self.save_fold_info:
            fold_data = {
                "n_splits": self.n_splits,
                "stratified": self.stratified,
                "seed": self.seed,
                "total_samples": len(labels),
                "class_distribution": {"negative": int(np.sum(labels == 0)), "positive": int(np.sum(labels == 1))},
                "folds": [],
            }

            for fold_idx, (train_idx, val_idx) in enumerate(splits):
                fold_info = {
                    "fold": fold_idx,
                    "train": train_idx.tolist(),
                    "val": val_idx.tolist(),
                    "train_size": len(train_idx),
                    "val_size": len(val_idx),
                    "train_pos_ratio": float(np.mean(labels[train_idx])),
                    "val_pos_ratio": float(np.mean(labels[val_idx])),
                }
                fold_data["folds"].append(fold_info)

            with open(fold_file, "w") as f:
                json.dump(fold_data, f, indent=2)

            logger.info(f"K-fold splits saved to {fold_file}")

        return splits

    def _save_current_fold_info(self, train_indices: np.ndarray, val_indices: np.ndarray) -> None:
        """ä¿å­˜å½“å‰æŠ˜çš„è¯¦ç»†ä¿¡æ¯"""
        fold_info = {
            "fold": self.current_fold,
            "n_splits": self.n_splits,
            "train_indices": train_indices.tolist(),
            "val_indices": val_indices.tolist(),
            "train_size": len(train_indices),
            "val_size": len(val_indices),
            "seed": self.seed,
            "timestamp": pd.Timestamp.now().isoformat(),
        }

        current_fold_file = self.fold_info_dir / f"fold_{self.current_fold}_info.json"
        with open(current_fold_file, "w") as f:
            json.dump(fold_info, f, indent=2)

    def _create_transforms(self, stage: str) -> Optional[Callable]:
        """åˆ›å»ºæ•°æ®å˜æ¢ï¼ˆå ä½ç¬¦ï¼Œéœ€è¦æ ¹æ®å®é™…éœ€æ±‚å®ç°ï¼‰"""
        return None

    def train_dataloader(self) -> DataLoader:
        """åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨"""
        if self.train_dataset is None:
            raise RuntimeError("Training dataset not initialized. Call setup('fit') first.")

        return DataLoader(
            self.train_dataset,
            batch_size=self.batch_size,
            shuffle=self.shuffle_train,
            num_workers=self.num_workers,
            pin_memory=self.pin_memory,
            drop_last=False,
            persistent_workers=self.num_workers > 0,
        )

    def val_dataloader(self) -> DataLoader:
        """åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨"""
        if self.val_dataset is None:
            raise RuntimeError("Validation dataset not initialized. Call setup('fit') first.")

        return DataLoader(
            self.val_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers,
            pin_memory=self.pin_memory,
            drop_last=False,
            persistent_workers=self.num_workers > 0,
        )

    def test_dataloader(self) -> DataLoader:
        """åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨"""
        if self.test_dataset is None:
            raise RuntimeError("Test dataset not initialized. Call setup('test') first.")

        return DataLoader(
            self.test_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers,
            pin_memory=self.pin_memory,
            drop_last=False,
            persistent_workers=self.num_workers > 0,
        )

    def predict_dataloader(self) -> DataLoader:
        """åˆ›å»ºé¢„æµ‹æ•°æ®åŠ è½½å™¨"""
        return self.test_dataloader()

    def get_fold_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰æŠ˜ä¿¡æ¯"""
        return {
            "current_fold": self.current_fold,
            "n_splits": self.n_splits,
            "train_size": len(self.train_dataset) if self.train_dataset else 0,
            "val_size": len(self.val_dataset) if self.val_dataset else 0,
            "test_size": len(self.test_dataset) if self.test_dataset else 0,
        }

    def get_all_folds_info(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰æŠ˜çš„ä¿¡æ¯"""
        fold_file = self.fold_info_dir / f"{self.n_splits}fold_splits.json"
        if fold_file.exists():
            with open(fold_file, "r") as f:
                return json.load(f)["folds"]
        return []

    @property
    def is_last_fold(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ€åä¸€æŠ˜"""
        return self.current_fold == self.n_splits - 1

    def summary(self) -> None:
        """æ‰“å°KæŠ˜æ•°æ®æ¨¡å—æ‘˜è¦"""
        print("\n" + "=" * 60)
        print(f"K-Fold Cross Validation Data Module")
        print("=" * 60)
        print(f"Number of folds: {self.n_splits}")
        print(f"Current fold: {self.current_fold}")
        print(f"Stratified: {self.stratified}")
        print(f"Seed: {self.seed}")

        if self.fold_indices:
            train_indices, val_indices = self.fold_indices[self.current_fold]
            print(f"Current fold - Train: {len(train_indices)}, Val: {len(val_indices)}")

        print(f"Batch size: {self.batch_size}")
        print(f"Workers: {self.num_workers}")
        print("=" * 60 + "\n")


# ä¾¿åˆ©å‡½æ•°ï¼šåˆ›å»ºKæŠ˜æ•°æ®æ¨¡å—
def create_kfold_datamodule(config: Dict[str, Any], current_fold: int) -> KFoldDataModule:
    """
    ä»é…ç½®åˆ›å»ºKæŠ˜æ•°æ®æ¨¡å—çš„ä¾¿åˆ©å‡½æ•°

    Args:
        config: æ•°æ®æ¨¡å—é…ç½®
        current_fold: å½“å‰æŠ˜ç´¢å¼•

    Returns:
        é…ç½®å¥½çš„KæŠ˜æ•°æ®æ¨¡å—
    """
    config = deepcopy(config)
    config["current_fold"] = current_fold

    return KFoldDataModule(**config)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)

    # ç¤ºä¾‹é…ç½®
    config = {
        "train_data_dir": "dataset/train_data",
        "test_data_dir": "dataset/test_data",
        "train_csv": "dataset/Train.csv",
        "test_csv": "dataset/Test.csv",
        "n_splits": 5,
        "current_fold": 0,
        "batch_size": 16,
        "num_workers": 4,
    }

    # åˆ›å»ºKæŠ˜æ•°æ®æ¨¡å—
    dm = KFoldDataModule(**config)
    dm.prepare_data()
    dm.setup("fit")
    dm.summary()

    print("âœ“ KFoldDataModule test completed!")
