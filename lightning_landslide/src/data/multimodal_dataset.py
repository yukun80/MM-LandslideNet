import torch
import numpy as np
import pandas as pd
from torch.utils.data import Dataset
from pathlib import Path
import logging
from typing import Tuple, Optional, Callable, List, Dict, Any, Union
import json

logger = logging.getLogger(__name__)


class MultiModalDataset(Dataset):
    """
    å…‰å­¦é¥æ„Ÿæ•°æ®é›†ç±»

    è¿™ä¸ªç±»ä¸“é—¨å¤„ç†æ‚¨é¡¹ç›®ä¸­çš„å¤šé€šé“é¥æ„Ÿæ•°æ®ã€‚å®ƒçš„æ ¸å¿ƒèŒè´£æ˜¯ï¼š

    1. æ•°æ®åŠ è½½ï¼šä».npyæ–‡ä»¶åŠ è½½å¤šé€šé“æ•°æ®
    2. é€šé“å¤„ç†ï¼šæå–å¹¶ç»„åˆå…‰å­¦é€šé“
    3. NDVIè®¡ç®—ï¼šå®æ—¶è®¡ç®—å½’ä¸€åŒ–æ¤è¢«æŒ‡æ•°
    4. è´¨é‡æ§åˆ¶ï¼šè¿‡æ»¤ä½è´¨é‡æ ·æœ¬
    5. æ ‡ç­¾å¤„ç†ï¼šæ­£ç¡®å¤„ç†äºŒåˆ†ç±»æ ‡ç­¾

    """

    def __init__(
        self,
        data_dir: Union[str, Path],
        csv_file: Union[str, Path],
        exclude_ids_file: Optional[Union[str, Path]] = None,
        transform: Optional[Callable] = None,
        compute_ndvi: bool = True,
        cache_data: bool = True,
        channel_config: Optional[Dict] = None,
        usage_mode: str = "optical_only",
    ):
        """
        åˆå§‹åŒ–å…‰å­¦æ•°æ®é›†

        è¿™ä¸ªåˆå§‹åŒ–æ–¹æ³•è®¾è®¡å¾—éå¸¸çµæ´»ï¼Œæ—¢æ”¯æŒæ‚¨å½“å‰çš„æ•°æ®æ ¼å¼ï¼Œ
        ä¹Ÿä¸ºæœªæ¥çš„æ‰©å±•ç•™ä¸‹äº†ç©ºé—´ã€‚

        Args:
            data_dir: æ•°æ®æ–‡ä»¶ç›®å½•è·¯å¾„
            csv_file: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
            exclude_ids_file: éœ€è¦æ’é™¤çš„æ ·æœ¬IDæ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰
            transform: æ•°æ®å˜æ¢å‡½æ•°
            compute_ndvi: æ˜¯å¦è®¡ç®—NDVIé€šé“
            cache_data: æ˜¯å¦ç¼“å­˜æ•°æ®åˆ°å†…å­˜ï¼ˆå°æ•°æ®é›†æ—¶æœ‰ç”¨ï¼‰
            channel_config: è¾“å…¥æ•°æ®é€šé“é…ç½®
            usage_mode: ä½¿ç”¨æ¨¡å¼
        """
        logger.info("MultiModalDataset_init" + "-" * 100)
        # è·¯å¾„å¤„ç†
        self.data_dir = Path(data_dir)
        self.csv_file = Path(csv_file)

        # æ•°æ®å¤„ç†é…ç½®
        self.transform = transform
        self.compute_ndvi = compute_ndvi
        self.cache_data = cache_data

        self.channel_config = channel_config
        self.usage_mode = usage_mode
        self.active_channels = self._parse_active_channels()

        # è®¡ç®—æœ€ç»ˆé€šé“æ•°
        self.num_channels = len(self.active_channels)

        # æ•°æ®ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.data_cache = {} if cache_data else None

        # åŠ è½½æ ·æœ¬ç´¢å¼•å’Œæ ‡ç­¾
        self.data_index = self._load_data_index()

        # åŠ è½½æ’é™¤åˆ—è¡¨
        self.exclude_ids = self._load_exclude_ids(exclude_ids_file)

        # è¿‡æ»¤æ•°æ®
        self._filter_data()

        logger.info(f"ğŸ”¢ Active channels: {self.active_channels}, NDVI: {self.compute_ndvi}")
        logger.info(f"ğŸ”¢ Final channel count: {self.num_channels}")

    def _parse_active_channels(self) -> Dict[str, List[int]]:
        """è§£æå½“å‰ä½¿ç”¨æ¨¡å¼ä¸‹çš„æ´»è·ƒé€šé“"""
        mode_config = self.channel_config["usage_modes"][self.usage_mode]
        active_groups = mode_config["groups"]

        active_channels = []

        for group_name in active_groups:
            group_channels = self.channel_config["channel_groups"][group_name]
            active_channels.extend(group_channels)

        return active_channels

    def _load_data_index(self) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®ç´¢å¼•æ–‡ä»¶

        è¿™ä¸ªæ–¹æ³•è¯»å–CSVæ–‡ä»¶ï¼Œå»ºç«‹æ ·æœ¬IDåˆ°æ ‡ç­¾çš„æ˜ å°„ã€‚
        æˆ‘ä»¬è¿›è¡Œäº†ä¸€äº›æ•°æ®è´¨é‡æ£€æŸ¥ï¼Œç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®ã€‚

        Returns:
            åŒ…å«IDå’Œæ ‡ç­¾çš„DataFrame
        """
        df = pd.read_csv(self.csv_file)

        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾åˆ—ï¼ˆè®­ç»ƒé›†æœ‰ï¼Œæµ‹è¯•é›†å¯èƒ½æ²¡æœ‰ï¼‰
        self.has_labels = "label" in df.columns

        logger.info(f"ğŸ”¢ Loaded {len(df)} samples from CSV")
        return df.reset_index(drop=True)

    def _load_exclude_ids(self, exclude_ids_file: Optional[Union[str, Path]]) -> set:
        """
        åŠ è½½éœ€è¦æ’é™¤çš„æ ·æœ¬IDåˆ—è¡¨

        åœ¨æ•°æ®è´¨é‡åˆ†æé˜¶æ®µï¼Œæ‚¨å¯èƒ½å·²ç»è¯†åˆ«å‡ºäº†ä¸€äº›ä½è´¨é‡çš„æ ·æœ¬ã€‚
        è¿™ä¸ªæ–¹æ³•åŠ è½½è¿™äº›æ ·æœ¬çš„IDï¼Œç¡®ä¿å®ƒä»¬ä¸ä¼šç”¨äºè®­ç»ƒã€‚

        Args:
            exclude_ids_file: æ’é™¤åˆ—è¡¨æ–‡ä»¶è·¯å¾„

        Returns:
            éœ€è¦æ’é™¤çš„æ ·æœ¬IDé›†åˆ
        """
        if exclude_ids_file is None:
            return set()

        exclude_path = Path(exclude_ids_file)
        if not exclude_path.exists():
            logger.warning(f"Exclude IDs file not found: {exclude_path}")
            return set()

        with open(exclude_path, "r") as f:
            exclude_ids = json.load(f)

        exclude_set = set(exclude_ids.get("excluded_image_ids", []))

        logger.info(f"ğŸ‘®ğŸ”¢ Loaded {len(exclude_set)} samples to exclude")
        return exclude_set

    def _filter_data(self) -> None:
        """
        è¿‡æ»¤æ•°æ®ï¼Œç§»é™¤æ’é™¤åˆ—è¡¨ä¸­çš„æ ·æœ¬

        è¿™ä¸ªæ­¥éª¤ç¡®ä¿æˆ‘ä»¬åªå¤„ç†é«˜è´¨é‡çš„æ•°æ®æ ·æœ¬ã€‚
        """
        if not self.exclude_ids:
            return

        initial_count = len(self.data_index)

        # è¿‡æ»¤æ’é™¤æ ·æœ¬
        mask = ~self.data_index["ID"].isin(self.exclude_ids)
        self.data_index = self.data_index[mask].reset_index(drop=True)

        filtered_count = initial_count - len(self.data_index)
        logger.info(f"ğŸ‘®ğŸ”¢ Filtered out {filtered_count} low-quality samples")
        logger.info(f"ğŸ‘®ğŸ”¢ Remaining samples: {len(self.data_index)}")

    def __len__(self) -> int:
        """è¿”å›æ•°æ®é›†å¤§å°"""
        return len(self.data_index)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è·å–å•ä¸ªæ•°æ®æ ·æœ¬

        è¿™æ˜¯æ•°æ®é›†ç±»çš„æ ¸å¿ƒæ–¹æ³•ã€‚å®ƒçš„èŒè´£æ˜¯ï¼š
        1. åŠ è½½åŸå§‹æ•°æ®
        2. æå–å’Œå¤„ç†å…‰å­¦é€šé“
        3. è®¡ç®—NDVIï¼ˆå¦‚æœéœ€è¦ï¼‰
        4. åº”ç”¨æ•°æ®å˜æ¢
        5. è¿”å›æ ‡å‡†æ ¼å¼çš„æ•°æ®

        Args:
            idx: æ ·æœ¬ç´¢å¼•

        Returns:
            (data, label) å…ƒç»„ï¼Œå…¶ä¸­ï¼š
            - data: å½¢çŠ¶ä¸º (channels, height, width) çš„å¼ é‡
            - label: æ ‡ç­¾å¼ é‡
        """
        if idx >= len(self):
            raise IndexError(f"Index {idx} out of range for dataset size {len(self)}")

        # è·å–æ ·æœ¬ä¿¡æ¯
        """
        iloc æ˜¯ pandas ä¸­ç”¨äº æŒ‰ä½ç½®ï¼ˆpositionï¼‰ç´¢å¼• è¡Œçš„æ–¹æ³•ã€‚
        iloc[idx] è¿”å›çš„æ˜¯ç¬¬ idx è¡Œçš„æ•°æ®ï¼ˆæŒ‰æ•°å­—ä½ç½®ï¼Œä¸æ˜¯æŒ‰ IDï¼‰ã€‚
        ç»“æœæ˜¯ä¸€ä¸ª pandas.Seriesï¼ŒåŒ…å«è¯¥è¡Œçš„æ‰€æœ‰åˆ—å†…å®¹ã€‚
        """
        row = self.data_index.iloc[idx]
        sample_id = row["ID"]

        try:
            # ä»ç¼“å­˜æˆ–æ–‡ä»¶åŠ è½½æ•°æ®
            if self.data_cache is not None and sample_id in self.data_cache:
                data = self.data_cache[sample_id]
            else:
                data = self._load_sample_data(sample_id)
                if self.data_cache is not None:
                    self.data_cache[sample_id] = data

            # å¤„ç†æ ‡ç­¾
            if self.has_labels:
                label = torch.tensor(row["label"], dtype=torch.long)
            else:
                label = torch.tensor(-1, dtype=torch.long)  # æµ‹è¯•é›†çš„å ä½ç¬¦æ ‡ç­¾

            # åº”ç”¨å˜æ¢
            if self.transform is not None:
                data = self.transform(data)

            return data, label

        except Exception as e:
            logger.error(f"Error loading sample {sample_id}: {e}")
            raise e

    def _load_sample_data(self, sample_id: str) -> torch.Tensor:
        """
        åŠ è½½å¹¶å¤„ç†å•ä¸ªæ ·æœ¬å¤šæ¨¡æ€çš„æ•°æ®

        è¿™ä¸ªæ–¹æ³•å®ç°äº†æ‚¨åŸæœ‰æ•°æ®åŠ è½½é€»è¾‘çš„æ ¸å¿ƒéƒ¨åˆ†ï¼š
        1. åŠ è½½å¤šé€šé“.npyæ–‡ä»¶
        2. æå–æŒ‡å®šçš„å…‰å­¦é€šé“
        3. è®¡ç®—NDVIé€šé“
        4. ç»„åˆæˆæœ€ç»ˆçš„å¤šé€šé“æ•°æ®

        Args:
            sample_id: æ ·æœ¬ID

        Returns:
            å¤„ç†åçš„æ•°æ®å¼ é‡ï¼Œå½¢çŠ¶ä¸º (channels, height, width)
        """

        # æ„é€ æ•°æ®æ–‡ä»¶è·¯å¾„
        data_path = self.data_dir / f"{sample_id}.npy"

        if not data_path.exists():
            raise FileNotFoundError(f"Data file not found: {data_path}")

        # åŠ è½½åŸå§‹æ•°æ®
        raw_data = np.load(data_path)  # å½¢çŠ¶é€šå¸¸æ˜¯ (12, 64, 64)

        # ç¡®ä¿æ•°æ®å½¢çŠ¶ä¸º (channels, height, width)
        if raw_data.shape[-1] == 12:  # (64, 64, 12) â†’ (12, 64, 64)
            raw_data = np.transpose(raw_data, (2, 0, 1))

        # æ ¹æ®é…ç½®é€‰æ‹©é€šé“
        selected_channels = []

        for channel in self.active_channels:
            if channel == "ndvi" and self.compute_ndvi:
                # è®¡ç®—NDVI
                optical_channels = self.channel_config["channel_groups"]["optical"]
                red_idx, nir_idx = optical_channels[0], optical_channels[3]
                ndvi = self._compute_ndvi(raw_data[red_idx], raw_data[nir_idx])
                selected_channels.append(ndvi)
            else:
                selected_channels.append(raw_data[channel])

        # å †å æ‰€æœ‰é€šé“
        final_data = np.stack(selected_channels, axis=0)  # (channels, height, width)

        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        data_tensor = torch.from_numpy(final_data).float()

        return data_tensor

    def _compute_ndvi(self, red: np.ndarray, nir: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—å½’ä¸€åŒ–æ¤è¢«æŒ‡æ•° (NDVI)

        NDVIæ˜¯é¥æ„Ÿä¸­æœ€é‡è¦çš„æ¤è¢«æŒ‡æ•°ä¹‹ä¸€ï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š
        NDVI = (NIR - Red) / (NIR + Red)

        åœ¨æ»‘å¡æ£€æµ‹ä¸­ï¼ŒNDVIç‰¹åˆ«æœ‰ç”¨ï¼Œå› ä¸ºï¼š
        1. æ»‘å¡åŒºåŸŸé€šå¸¸æ¤è¢«è¦†ç›–è¾ƒå°‘
        2. NDVIèƒ½å¤Ÿçªå‡ºæ¤è¢«ä¸è£¸åœŸçš„å·®å¼‚
        3. æ—¶é—´åºåˆ—NDVIå˜åŒ–èƒ½æŒ‡ç¤ºåœ°è¡¨æ‰°åŠ¨

        Args:
            red: çº¢å…‰é€šé“
            nir: è¿‘çº¢å¤–é€šé“

        Returns:
            NDVIæ•°ç»„ï¼Œå½¢çŠ¶ä¸è¾“å…¥é€šé“ç›¸åŒ

        è°ƒç”¨å‡½æ•°ï¼š
            _load_sample_data
        """

        # æå–çº¢å…‰å’Œè¿‘çº¢å¤–é€šé“
        red = red.astype(np.float32)  # Redé€šé“
        nir = nir.astype(np.float32)  # NIRé€šé“

        # è®¡ç®—NDVIï¼Œæ·»åŠ å°å¸¸æ•°é¿å…é™¤é›¶
        epsilon = 1e-8
        ndvi = (nir - red) / (nir + red + epsilon)

        # å°†NDVIé™åˆ¶åœ¨åˆç†èŒƒå›´å†… [-1, 1]
        ndvi = np.clip(ndvi, -1.0, 1.0)

        return ndvi


# ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºä¸åŒé…ç½®çš„æ•°æ®é›†
def create_train_dataset(
    data_dir: str,
    csv_file: str,
    exclude_ids_file: str = None,
    transform: Callable = None,
    channel_config: Optional[Dict] = None,
    usage_mode: str = "optical_only",
) -> MultiModalDataset:

    # éªŒè¯usage_modeçš„æœ‰æ•ˆæ€§
    valid_modes = channel_config.get("usage_modes", {}).keys()
    if usage_mode not in valid_modes:
        raise ValueError(f"Invalid usage_mode: {usage_mode}. Valid options: {list(valid_modes)}")

    """åˆ›å»ºè®­ç»ƒæ•°æ®é›†"""
    return MultiModalDataset(
        data_dir=data_dir,
        csv_file=csv_file,
        exclude_ids_file=exclude_ids_file,
        transform=transform,
        compute_ndvi=True,
        cache_data=True,
        channel_config=channel_config,
        usage_mode=usage_mode,
    )


def create_test_dataset(
    data_dir: str,
    csv_file: str,
    transform: Callable = None,
    channel_config: Optional[Dict] = None,
    usage_mode: str = "optical_only",
) -> MultiModalDataset:
    """åˆ›å»ºæµ‹è¯•æ•°æ®é›†"""
    return MultiModalDataset(
        data_dir=data_dir,
        csv_file=csv_file,
        exclude_ids_file=None,
        transform=transform,
        compute_ndvi=True,
        cache_data=True,
        channel_config=channel_config,
        usage_mode=usage_mode,
    )
