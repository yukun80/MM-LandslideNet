# =============================================================================
# lightning_landslide/src/training/simple_kfold_trainer.py - ç®€åŒ–KæŠ˜è®­ç»ƒå™¨
# =============================================================================

"""
ç®€åŒ–çš„KæŠ˜äº¤å‰éªŒè¯è®­ç»ƒå™¨

è®¾è®¡å“²å­¦ï¼š"ç®€å•å³ç¾"
è¿™ä¸ªè®­ç»ƒå™¨çš„è®¾è®¡åŸåˆ™æ˜¯æœ€å¤§åŒ–é‡ç”¨ç°æœ‰çš„è®­ç»ƒæµç¨‹ï¼Œ
æœ€å°åŒ–æ–°å¢çš„å¤æ‚æ€§ã€‚

æ ¸å¿ƒæ€æƒ³ï¼š
KæŠ˜è®­ç»ƒ = æ ‡å‡†è®­ç»ƒ Ã— Næ¬¡ + ç»“æœèšåˆ
å°±åƒåšNä¸ªè›‹ç³•ï¼Œæ¯ä¸ªè›‹ç³•çš„åˆ¶ä½œæµç¨‹å®Œå…¨ç›¸åŒï¼Œ
åªæ˜¯åŸæ–™ï¼ˆæ•°æ®ï¼‰åˆ†é…ä¸åŒï¼Œæœ€åç»Ÿè®¡æ‰€æœ‰è›‹ç³•çš„è´¨é‡ã€‚
"""

import torch
import numpy as np
import pandas as pd
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
import json
import time
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger

from ..data.kfold_extension import create_kfold_wrapper
from ..utils.instantiate import instantiate_from_config

logger = logging.getLogger(__name__)


class SimpleKFoldTrainer:
    """
    ç®€åŒ–çš„KæŠ˜äº¤å‰éªŒè¯è®­ç»ƒå™¨

    è¿™ä¸ªç±»çš„è®¾è®¡éµå¾ª"ç»„åˆä¼˜äºç»§æ‰¿"çš„åŸåˆ™ã€‚
    å®ƒä¸æ˜¯ä¸€ä¸ªLightningè®­ç»ƒå™¨çš„å­ç±»ï¼Œè€Œæ˜¯ä¸€ä¸ªåè°ƒå™¨ï¼Œ
    è´Ÿè´£ç®¡ç†å¤šä¸ªæ ‡å‡†è®­ç»ƒè¿‡ç¨‹ã€‚

    å°±åƒä¸€ä¸ªé¡¹ç›®ç»ç†ï¼Œä¸éœ€è¦äº²è‡ªåšæ¯ä¸€é¡¹å…·ä½“å·¥ä½œï¼Œ
    ä½†éœ€è¦åè°ƒå„ä¸ªéƒ¨é—¨ï¼ˆæ•°æ®ã€æ¨¡å‹ã€è®­ç»ƒï¼‰å®Œæˆæ•´ä½“ç›®æ ‡ã€‚
    """

    def __init__(self, config: Dict[str, Any], experiment_name: str = None, output_dir: str = None):
        """
        åˆå§‹åŒ–ç®€åŒ–KæŠ˜è®­ç»ƒå™¨

        Args:
            config: å®Œæ•´çš„è®­ç»ƒé…ç½®ï¼ˆåŒ…å«model, data, trainer, kfoldç­‰ï¼‰
            experiment_name: å®éªŒåç§°
            output_dir: å®éªŒè¾“å‡ºç›®å½•çš„å®Œæ•´è·¯å¾„ï¼ˆä¸åŸºç¡€è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
        """
        self.config = config
        self.kfold_config = config.get("kfold", {})

        # KæŠ˜åŸºæœ¬é…ç½®
        self.n_splits = self.kfold_config.get("n_splits", 5)
        self.stratified = self.kfold_config.get("stratified", True)
        self.primary_metric = self.kfold_config.get("primary_metric", "f1")
        self.save_oof = self.kfold_config.get("save_oof_predictions", True)
        self.save_models = self.kfold_config.get("save_fold_models", True)

        # å®éªŒç®¡ç†
        self.experiment_name = experiment_name or config.get("experiment_name", f"kfold_{int(time.time())}")

        # ä½¿ç”¨ä¼ å…¥çš„output_dirï¼ˆå®Œæ•´è·¯å¾„ï¼‰ï¼Œè€Œä¸æ˜¯å†æ¬¡åµŒå¥—experiment_name
        if output_dir is not None:
            self.output_dir = Path(output_dir)
        else:
            # å¦‚æœæ²¡æœ‰æä¾›output_dirï¼Œå›é€€åˆ°é»˜è®¤è·¯å¾„ï¼ˆå‘åå…¼å®¹ï¼‰
            self.output_dir = Path("outputs") / self.experiment_name

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ç»“æœå­˜å‚¨
        self.fold_results = []
        self.oof_predictions = None
        self.oof_targets = None
        self.test_predictions = []

        # å…¨å±€ç§å­
        self.seed = config.get("seed", 3407)
        pl.seed_everything(self.seed, workers=True)

        logger.info(f"ğŸš€ SimpleKFoldTrainer initialized")
        logger.info(f"ğŸ“ Experiment: {self.experiment_name}")
        logger.info(f"ğŸ¯ {self.n_splits}-fold cross validation")
        logger.info(f"ğŸ“Š Primary metric: {self.primary_metric}")

        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        self._setup_directories()

    def _setup_directories(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„"""
        dirs = ["models", "predictions", "logs", "plots", "reports"]
        for dir_name in dirs:
            (self.output_dir / dir_name).mkdir(exist_ok=True)

        logger.info(f"ğŸ“‚ Output directories created in: {self.output_dir}")

    def run_kfold_training(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„KæŠ˜äº¤å‰éªŒè¯è®­ç»ƒ

        è¿™æ˜¯æ•´ä¸ªç±»çš„æ ¸å¿ƒæ–¹æ³•ã€‚å®ƒçš„é€»è¾‘éå¸¸ç›´è§‚ï¼š
        1. å‡†å¤‡æ•°æ®åˆ†å‰²
        2. å¾ªç¯è®­ç»ƒæ¯ä¸€æŠ˜
        3. æ”¶é›†å’Œåˆ†æç»“æœ
        4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š

        Returns:
            åŒ…å«æ‰€æœ‰ç»“æœçš„å­—å…¸
        """
        logger.info(f"ğŸ¯ Starting {self.n_splits}-fold cross validation")
        start_time = time.time()

        # ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡KæŠ˜æ•°æ®åˆ†å‰²
        logger.info("ğŸ“Š Step 1: Preparing K-fold data splits...")
        kfold_wrapper = self._create_kfold_wrapper()
        kfold_wrapper.prepare_fold_splits()

        # ç¬¬äºŒæ­¥ï¼šè®­ç»ƒæ¯ä¸€æŠ˜
        logger.info("ğŸ”„ Step 2: Training individual folds...")
        for fold in range(self.n_splits):
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ”„ Training Fold {fold + 1}/{self.n_splits}")
            logger.info(f"{'='*60}")

            fold_result = self._train_single_fold(fold, kfold_wrapper)
            self.fold_results.append(fold_result)

            # æ‰“å°å½“å‰æŠ˜ç»“æœ
            val_score = fold_result["val_metrics"].get(f"val_{self.primary_metric}", 0)
            logger.info(f"âœ… Fold {fold + 1} - {self.primary_metric}: {val_score:.4f}")

        # ç¬¬ä¸‰æ­¥ï¼šç”ŸæˆOOFé¢„æµ‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.save_oof:
            logger.info("ğŸ¯ Step 3: Generating OOF predictions...")
            self._generate_oof_predictions(kfold_wrapper)

        # ç¬¬å››æ­¥ï¼šç”Ÿæˆæœ€ç»ˆç»“æœå’ŒæŠ¥å‘Š
        logger.info("ğŸ“Š Step 4: Generating final results...")
        final_results = self._generate_final_results(time.time() - start_time)

        # ç¬¬äº”æ­¥ï¼šä¿å­˜ç»“æœ
        logger.info("ğŸ’¾ Step 5: Saving results...")
        self._save_results(final_results)

        # ç¬¬å…­æ­¥ï¼šç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
        logger.info("ğŸ“ˆ Step 6: Generating visualization report...")
        self._generate_report()

        logger.info(f"\nğŸ‰ K-Fold training completed!")
        logger.info(f"â±ï¸  Total time: {final_results['total_time']:.2f}s")
        logger.info(f"ğŸ“ˆ Mean CV score: {final_results['mean_cv_score']:.4f} Â± {final_results['std_cv_score']:.4f}")

        return final_results

    def _create_kfold_wrapper(self):
        """åˆ›å»ºKæŠ˜æ•°æ®åŒ…è£…å™¨"""
        return create_kfold_wrapper(
            base_datamodule_config=self.config["data"]["params"],
            n_splits=self.n_splits,
            stratified=self.stratified,
            seed=self.seed,
            output_dir=str(self.output_dir / "kfold_info"),
        )

    def _train_single_fold(self, fold_idx: int, kfold_wrapper) -> Dict[str, Any]:
        """
        è®­ç»ƒå•ä¸ªæŠ˜

        è¿™ä¸ªæ–¹æ³•å±•ç¤ºäº†è®¾è®¡çš„æ ¸å¿ƒæ€æƒ³ï¼šé‡ç”¨ç°æœ‰è®­ç»ƒæµç¨‹ã€‚
        æˆ‘ä»¬ä¸éœ€è¦é‡æ–°å‘æ˜è®­ç»ƒé€»è¾‘ï¼Œåªéœ€è¦ï¼š
        1. è·å–å½“å‰æŠ˜çš„æ•°æ®æ¨¡å—
        2. åˆ›å»ºæ¨¡å‹
        3. é…ç½®å›è°ƒå’Œæ—¥å¿—
        4. æ‰§è¡Œæ ‡å‡†è®­ç»ƒ

        Args:
            fold_idx: æŠ˜ç´¢å¼•
            kfold_wrapper: KæŠ˜æ•°æ®åŒ…è£…å™¨

        Returns:
            å•æŠ˜è®­ç»ƒç»“æœ
        """
        # è®¾ç½®æŠ˜ç‰¹å®šçš„éšæœºç§å­
        fold_seed = self.seed + fold_idx
        pl.seed_everything(fold_seed, workers=True)

        # è·å–å½“å‰æŠ˜çš„æ•°æ®æ¨¡å—
        datamodule = kfold_wrapper.get_fold_datamodule(fold_idx)

        # åˆ›å»ºæ¨¡å‹ï¼ˆæ¯æŠ˜éƒ½æ˜¯å…¨æ–°çš„æ¨¡å‹ï¼‰
        model = instantiate_from_config(self.config["model"])

        # è®¾ç½®å›è°ƒå‡½æ•°
        callbacks = self._create_fold_callbacks(fold_idx)

        # è®¾ç½®æ—¥å¿—è®°å½•å™¨
        logger_instance = TensorBoardLogger(
            save_dir=str(self.output_dir / "logs"),
            name=f"fold_{fold_idx}",
            version="",
        )

        # åˆ›å»ºè®­ç»ƒå™¨ - æ¨¡ä»¿æ ‡å‡†è®­ç»ƒçš„æ­£ç¡®åšæ³•
        trainer_config = self.config["trainer"]["params"].copy()
        trainer = pl.Trainer(**trainer_config)

        # ç„¶åè®¾ç½®å¤æ‚å¯¹è±¡ï¼ˆå°±åƒæ ‡å‡†è®­ç»ƒä¸­çš„åšæ³•ï¼‰
        if callbacks:
            trainer.callbacks = callbacks
        if logger_instance:
            trainer.logger = logger_instance

        # æ‰§è¡Œè®­ç»ƒ - è¿™é‡Œå°±æ˜¯æ ‡å‡†çš„Lightningè®­ç»ƒæµç¨‹
        trainer.fit(model, datamodule)

        # æ‰§è¡ŒéªŒè¯è·å–æœ€ç»ˆæŒ‡æ ‡
        val_results = trainer.validate(model, datamodule, verbose=False)
        val_metrics = val_results[0] if val_results else {}

        # ä¿å­˜æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        model_path = None
        if self.save_models:
            model_path = self.output_dir / "models" / f"fold_{fold_idx}_model.ckpt"
            trainer.save_checkpoint(str(model_path))

        return {
            "fold": fold_idx,
            "val_metrics": val_metrics,
            "model_path": str(model_path) if model_path else None,
            "trainer": trainer,
            "model": model,
        }

    def _create_fold_callbacks(self, fold_idx: int) -> List[pl.Callback]:
        """
        ä¸ºå•æŠ˜åˆ›å»ºå›è°ƒå‡½æ•°

        è¿™ä¸ªæ–¹æ³•å±•ç¤ºäº†å¦‚ä½•é‡ç”¨é…ç½®ä¸­çš„å›è°ƒè®¾ç½®ï¼Œ
        ä½†ä¸ºæ¯ä¸€æŠ˜è¿›è¡Œä¸ªæ€§åŒ–é…ç½®ã€‚
        """
        callbacks = []

        # æ¨¡å‹æ£€æŸ¥ç‚¹å›è°ƒ
        if "callbacks" in self.config and "model_checkpoint" in self.config["callbacks"]:
            checkpoint_config = self.config["callbacks"]["model_checkpoint"]

            # ä»é…ç½®ä¸­è¯»å–æ‰€æœ‰å‚æ•°ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 
            monitor_metric = checkpoint_config.get("monitor", f"val_{self.primary_metric}")
            mode = checkpoint_config.get("mode", "max")
            save_top_k = checkpoint_config.get("save_top_k", 1)
            save_last = checkpoint_config.get("save_last", True)
            verbose = checkpoint_config.get("verbose", True)

            # å…³é”®ä¿®å¤ï¼šæ­£ç¡®è¯»å–min_deltaå‚æ•°
            min_delta = checkpoint_config.get("min_delta", 0.0)  # é»˜è®¤å€¼åº”è¯¥å’ŒLightningä¸€è‡´

            checkpoint_callback = ModelCheckpoint(
                dirpath=str(self.output_dir / "models"),
                filename=f"fold_{fold_idx}_best_{{epoch:02d}}_{{val_{self.primary_metric}:.4f}}",
                monitor=monitor_metric,
                mode=mode,
                save_top_k=save_top_k,
                save_last=save_last,
                verbose=verbose,
                min_delta=min_delta,  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
            )
            callbacks.append(checkpoint_callback)

        # æ—©åœå›è°ƒ
        if "callbacks" in self.config and "early_stopping" in self.config["callbacks"]:
            early_stop_config = self.config["callbacks"]["early_stopping"]

            # ä»é…ç½®ä¸­è¯»å–æ‰€æœ‰å‚æ•°
            monitor_metric = early_stop_config.get("monitor", f"val_{self.primary_metric}")
            mode = early_stop_config.get("mode", "max")
            patience = early_stop_config.get("patience", 10)
            verbose = early_stop_config.get("verbose", True)

            # å…³é”®ä¿®å¤ï¼šåŒæ ·éœ€è¦è¯»å–min_deltaå‚æ•°
            min_delta = early_stop_config.get("min_delta", 0.0)

            early_stopping = EarlyStopping(
                monitor=monitor_metric,
                mode=mode,
                patience=patience,
                verbose=verbose,
                min_delta=min_delta,  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
            )
            callbacks.append(early_stopping)

        return callbacks

    def _generate_oof_predictions(self, kfold_wrapper):
        """
        ç”ŸæˆOOFï¼ˆOut-of-Foldï¼‰é¢„æµ‹

        OOFé¢„æµ‹æ˜¯kæŠ˜äº¤å‰éªŒè¯çš„ç²¾é«“ä¹‹ä¸€ã€‚
        å®ƒçš„æ€æƒ³æ˜¯ï¼šå¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨æ²¡æœ‰è§è¿‡å®ƒçš„æ¨¡å‹æ¥é¢„æµ‹ã€‚
        è¿™æ ·å¾—åˆ°çš„é¢„æµ‹ç»“æœæ›´èƒ½åæ˜ æ¨¡å‹çš„çœŸå®æ³›åŒ–èƒ½åŠ›ã€‚

        å°±åƒè€ƒè¯•ä¸€æ ·ï¼Œæˆ‘ä»¬ç”¨å­¦ç”Ÿæ²¡æœ‰è§è¿‡çš„é¢˜ç›®æ¥æµ‹è¯•ä»–ä»¬çš„çœŸå®æ°´å¹³ã€‚
        """
        logger.info("ğŸ¯ Generating OOF predictions...")

        # å‡†å¤‡OOFæ•°ç»„
        # æˆ‘ä»¬éœ€è¦çŸ¥é“æ€»å…±æœ‰å¤šå°‘è®­ç»ƒæ ·æœ¬
        temp_datamodule = kfold_wrapper.get_fold_datamodule(0)

        # ä»æŠ˜åˆ†å‰²ä¿¡æ¯ä¸­è·å–æ€»æ ·æœ¬æ•°
        total_samples = sum(len(train_idx) + len(val_idx) for train_idx, val_idx in kfold_wrapper.fold_splits)

        self.oof_predictions = np.zeros(total_samples)
        self.oof_targets = np.zeros(total_samples)

        # ä¸ºæ¯ä¸€æŠ˜ç”ŸæˆOOFé¢„æµ‹
        for fold_idx in range(self.n_splits):
            logger.info(f"Generating OOF predictions for fold {fold_idx}...")

            # è·å–éªŒè¯é›†ç´¢å¼•
            _, val_indices = kfold_wrapper.fold_splits[fold_idx]

            # è·å–å¯¹åº”çš„æ¨¡å‹å’Œæ•°æ®
            fold_result = self.fold_results[fold_idx]
            model = fold_result["model"]
            trainer = fold_result["trainer"]

            # è·å–éªŒè¯æ•°æ®
            datamodule = kfold_wrapper.get_fold_datamodule(fold_idx)

            # ç”Ÿæˆé¢„æµ‹
            model.eval()
            predictions = []
            targets = []

            with torch.no_grad():
                for batch in datamodule.val_dataloader():
                    if isinstance(batch, (list, tuple)) and len(batch) == 2:
                        x, y = batch
                        targets.extend(y.cpu().numpy())
                    else:
                        x = batch

                    # ç”Ÿæˆé¢„æµ‹
                    logits = model(x.to(model.device))
                    probs = torch.sigmoid(logits).cpu().numpy().flatten()
                    predictions.extend(probs)

            # å­˜å‚¨OOFé¢„æµ‹
            self.oof_predictions[val_indices] = predictions
            if targets:  # å¦‚æœæœ‰æ ‡ç­¾
                self.oof_targets[val_indices] = targets

        logger.info("âœ… OOF predictions generated!")

    def _generate_final_results(self, total_time: float) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆç»“æœ"""
        # æ”¶é›†æ‰€æœ‰æŠ˜çš„éªŒè¯æŒ‡æ ‡
        cv_scores = []
        all_metrics = {}

        for fold_result in self.fold_results:
            val_metrics = fold_result["val_metrics"]
            fold_score = val_metrics.get(f"val_{self.primary_metric}", 0)
            cv_scores.append(fold_score)

            # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
            for metric_name, value in val_metrics.items():
                if metric_name not in all_metrics:
                    all_metrics[metric_name] = []
                all_metrics[metric_name].append(value)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        mean_cv_score = np.mean(cv_scores)
        std_cv_score = np.std(cv_scores)

        # è®¡ç®—æ¯ä¸ªæŒ‡æ ‡çš„ç»Ÿè®¡ä¿¡æ¯
        metrics_stats = {}
        for metric_name, values in all_metrics.items():
            metrics_stats[metric_name] = {
                "mean": float(np.mean(values)),
                "std": float(np.std(values)),
                "values": values,
            }

        # ç»„è£…æœ€ç»ˆç»“æœ
        final_results = {
            "experiment_name": self.experiment_name,
            "n_splits": self.n_splits,
            "primary_metric": self.primary_metric,
            "mean_cv_score": float(mean_cv_score),
            "std_cv_score": float(std_cv_score),
            "cv_scores": cv_scores,
            "metrics_stats": metrics_stats,
            "total_time": total_time,
            "timestamp": datetime.now().isoformat(),
            "config": self.config,
        }

        return final_results

    def _save_results(self, results: Dict[str, Any]):
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        results_file = self.output_dir / "kfold_results.json"

        # åˆ›å»ºä¸€ä¸ªå¯åºåˆ—åŒ–çš„ç»“æœå‰¯æœ¬
        serializable_results = results.copy()
        # ç§»é™¤ä¸èƒ½åºåˆ—åŒ–çš„é…ç½®å¯¹è±¡
        if "config" in serializable_results:
            serializable_results["config"] = str(serializable_results["config"])

        with open(results_file, "w") as f:
            json.dump(serializable_results, f, indent=2)

        logger.info(f"ğŸ’¾ Results saved to: {results_file}")

    def _generate_report(self):
        """ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š"""
        try:
            # åˆ›å»ºå›¾è¡¨
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))

            # 1. CVåˆ†æ•°åˆ†å¸ƒ
            cv_scores = [result["val_metrics"].get(f"val_{self.primary_metric}", 0) for result in self.fold_results]

            axes[0, 0].bar(range(1, self.n_splits + 1), cv_scores)
            axes[0, 0].set_title(f"{self.primary_metric} Score by Fold")
            axes[0, 0].set_xlabel("Fold")
            axes[0, 0].set_ylabel(f"{self.primary_metric}")
            axes[0, 0].grid(True, alpha=0.3)

            # 2. CVåˆ†æ•°ç®±çº¿å›¾
            axes[0, 1].boxplot([cv_scores])
            axes[0, 1].set_title(f"{self.primary_metric} Distribution")
            axes[0, 1].set_ylabel(f"{self.primary_metric}")
            axes[0, 1].grid(True, alpha=0.3)

            # 3. å¦‚æœæœ‰OOFé¢„æµ‹ï¼Œç»˜åˆ¶ROCæ›²çº¿
            if self.oof_predictions is not None and self.oof_targets is not None:
                from sklearn.metrics import roc_curve, auc

                fpr, tpr, _ = roc_curve(self.oof_targets, self.oof_predictions)
                roc_auc = auc(fpr, tpr)

                axes[1, 0].plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.3f})")
                axes[1, 0].plot([0, 1], [0, 1], "k--")
                axes[1, 0].set_xlabel("False Positive Rate")
                axes[1, 0].set_ylabel("True Positive Rate")
                axes[1, 0].set_title("OOF ROC Curve")
                axes[1, 0].legend()
                axes[1, 0].grid(True, alpha=0.3)
            else:
                axes[1, 0].text(
                    0.5, 0.5, "OOF predictions not available", ha="center", va="center", transform=axes[1, 0].transAxes
                )

            # 4. è®­ç»ƒæ—¶é—´å¯¹æ¯”ï¼ˆå¦‚æœå¯è·å¾—ï¼‰
            axes[1, 1].text(
                0.5,
                0.5,
                f"Mean CV Score:\n{np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}",
                ha="center",
                va="center",
                transform=axes[1, 1].transAxes,
                fontsize=14,
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"),
            )
            axes[1, 1].set_title("Summary Statistics")

            plt.tight_layout()

            # ä¿å­˜å›¾è¡¨
            plot_file = self.output_dir / "plots" / "kfold_report.png"
            plt.savefig(plot_file, dpi=300, bbox_inches="tight")
            plt.close()

            logger.info(f"ğŸ“Š Visualization report saved to: {plot_file}")

        except Exception as e:
            logger.warning(f"âš ï¸  Could not generate visualization report: {e}")


# ä¾¿åˆ©å‡½æ•°
def run_kfold_training(config: Dict[str, Any], experiment_name: str = None) -> Dict[str, Any]:
    """
    è¿è¡ŒKæŠ˜è®­ç»ƒçš„ä¾¿åˆ©å‡½æ•°

    è¿™ä¸ªå‡½æ•°ä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªç®€å•çš„æ¥å£æ¥æ‰§è¡ŒKæŠ˜è®­ç»ƒã€‚
    å°±åƒä¸€ä¸ªé¥æ§å™¨ï¼Œç”¨æˆ·åªéœ€è¦æŒ‰ä¸€ä¸ªæŒ‰é’®å°±èƒ½å¯åŠ¨æ•´ä¸ªå¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ã€‚

    Args:
        config: è®­ç»ƒé…ç½®
        experiment_name: å®éªŒåç§°

    Returns:
        è®­ç»ƒç»“æœ
    """
    trainer = SimpleKFoldTrainer(config, experiment_name)
    return trainer.run_kfold_training()


if __name__ == "__main__":
    print("âœ… SimpleKFoldTrainer ready for Kaggle-level cross validation!")
    print("ğŸš€ Use run_kfold_training(config) to start training!")
