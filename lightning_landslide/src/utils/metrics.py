# =============================================================================
# src/utils/metrics.py - è‡ªå®šä¹‰æŒ‡æ ‡å’Œå›è°ƒ
# =============================================================================

"""
è‡ªå®šä¹‰æŒ‡æ ‡å’Œå›è°ƒå‡½æ•°

è¿™ä¸ªæ¨¡å—æä¾›äº†é¢å¤–çš„æŒ‡æ ‡è®¡ç®—å’Œå›è°ƒåŠŸèƒ½ï¼Œè¡¥å……Lightningå†…ç½®çš„åŠŸèƒ½ã€‚
ç‰¹åˆ«é’ˆå¯¹æ»‘å¡æ£€æµ‹ä»»åŠ¡çš„ç‰¹æ®Šéœ€æ±‚è¿›è¡Œäº†ä¼˜åŒ–ã€‚
"""

import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks import Callback
import numpy as np
from typing import Dict, Any, Optional, List
import logging
from pathlib import Path
import json
import time
from datetime import datetime

logger = logging.getLogger(__name__)


class MetricsLogger(Callback):
    """
    è‡ªå®šä¹‰æŒ‡æ ‡æ—¥å¿—å›è°ƒ

    è¿™ä¸ªå›è°ƒæ‰©å±•äº†Lightningçš„æ—¥å¿—åŠŸèƒ½ï¼Œæä¾›ï¼š
    1. æ›´è¯¦ç»†çš„æŒ‡æ ‡è®°å½•
    2. å®æ—¶æ€§èƒ½ç›‘æ§
    3. è‡ªåŠ¨çš„æ¨¡å‹æ€§èƒ½åˆ†æ
    4. è®­ç»ƒè¿‡ç¨‹çš„ç»Ÿè®¡ä¿¡æ¯
    """

    # def __init__(self, log_dir: Optional[str] = None):
    def __init__(
        self,
        log_dir: Optional[str] = None,
        summary_interval: int = 10,
        save_history: bool = True,
    ):
        """
        åˆå§‹åŒ–MetricsLogger

        Args:
            log_dir: è‡ªå®šä¹‰æ—¥å¿—ä¿å­˜ç›®å½•ã€‚å¦‚æœä¸ºNoneï¼Œä¼šå°è¯•ä½¿ç”¨trainer.log_dir
        """
        super().__init__()
        self.custom_log_dir = Path(log_dir) if log_dir else None
        self.summary_interval = summary_interval
        self.save_history = save_history

        self.best_metrics = {}
        self.metrics_history = [] if self.save_history else None
        self.epoch_times = []
        self.training_start_time = None

        # å½“å‰epochæ•°æ®
        self.current_epoch_start_time = None

    def on_train_start(self, trainer, pl_module):
        """è®­ç»ƒepochå¼€å§‹æ—¶è®°å½•æ—¶é—´"""
        self.training_start_time = time.time()
        logger.info("ğŸš€ MetricsLogger: Training started")
        logger.info(f"ğŸ“Š Will save metrics to: {self.custom_log_dir}")

    def on_train_epoch_start(self, trainer, pl_module):
        """è®­ç»ƒepochå¼€å§‹æ—¶è®°å½•æ—¶é—´"""
        self.current_epoch_start_time = time.time()

    def on_train_epoch_end(self, trainer, pl_module):
        """è®­ç»ƒepochç»“æŸæ—¶çš„å¤„ç†"""
        # è®°å½•epochè€—æ—¶
        epoch_time = time.time() - self.current_epoch_start_time
        self.epoch_times.append(epoch_time)

        # è®°å½•åˆ°æ—¥å¿—
        pl_module.log("epoch_time_sec", epoch_time, on_epoch=True, logger=True)

    def on_validation_epoch_end(self, trainer, pl_module):
        """éªŒè¯epochç»“æŸæ—¶çš„å¤„ç†"""

        current_metrics = self._extract_metrics_safely(trainer, pl_module)
        if current_metrics is None:
            logger.warning(f"Epoch {trainer.current_epoch}: Failed to extract metrics")
            return

        self._update_best_metrics(current_metrics, trainer.current_epoch)

        # ä¿å­˜å†å²è®°å½•
        if self.save_history and self.metrics_history is not None:
            self.metrics_history.append(current_metrics)

        # å®šæœŸæ‰“å°è¯¦ç»†æ€»ç»“
        if trainer.current_epoch % self.summary_interval == 0:
            self._print_detailed_summary(trainer, current_metrics)

    def on_train_end(self, trainer, pl_module):
        """è®­ç»ƒç»“æŸæ—¶çš„æ€»ç»“å’Œä¿å­˜"""
        training_time = time.time() - self.training_start_time if self.training_start_time else 0

        # æ‰“å°æœ€ç»ˆæ€»ç»“
        self._print_final_summary(trainer, training_time)

        # ä¿å­˜å®Œæ•´æŠ¥å‘Š
        if self.save_history:
            self._save_experiment_report(trainer, training_time)

    def _extract_metrics_safely(self, trainer, pl_module) -> Optional[Dict[str, Any]]:
        """
        å®‰å…¨åœ°ä»Lightningç³»ç»Ÿä¸­æå–æŒ‡æ ‡

        Returns:
            æå–çš„æŒ‡æ ‡å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            logged_metrics = trainer.logged_metrics

            # è°ƒè¯•ä¿¡æ¯ï¼ˆä»…åœ¨éœ€è¦æ—¶å¼€å¯ï¼‰
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug(f"Available metric keys: {list(logged_metrics.keys())}")

            # æ„å»ºå½“å‰æŒ‡æ ‡å­—å…¸
            current_metrics = {
                "epoch": trainer.current_epoch,
                "timestamp": datetime.now().isoformat(),
            }

            # å…³é”®æŒ‡æ ‡æ˜ å°„ - å®šä¹‰æ‰€æœ‰å¯èƒ½çš„é”®å
            metric_mappings = {
                "train_loss": ["train_loss_epoch", "train_loss", "loss_epoch", "loss"],
                "val_loss": ["val_loss"],
                "val_f1": ["val_f1"],
                "val_acc": ["val_acc", "val_accuracy"],
                "val_precision": ["val_precision"],
                "val_recall": ["val_recall"],
                "val_auroc": ["val_auroc"],
                "learning_rate": ["lr", "learning_rate"],
            }

            # å®‰å…¨æå–æ¯ä¸ªæŒ‡æ ‡
            for metric_name, possible_keys in metric_mappings.items():
                value = self._safe_get_metric(logged_metrics, possible_keys)
                current_metrics[metric_name] = value

            # æ·»åŠ epochæ—¶é—´
            if self.epoch_times:
                current_metrics["epoch_time"] = self.epoch_times[-1]

            return current_metrics

        except Exception as e:
            logger.error(f"Error extracting metrics: {e}")
            return None

    def _safe_get_metric(self, metrics_dict: Dict, possible_keys: List[str]) -> Optional[float]:
        """
        å®‰å…¨è·å–æŒ‡æ ‡å€¼ï¼Œå¤„ç†å¤šç§å¯èƒ½çš„é”®åå’Œæ•°æ®ç±»å‹

        Args:
            metrics_dict: Lightningçš„logged_metricså­—å…¸
            possible_keys: å¯èƒ½çš„é”®ååˆ—è¡¨

        Returns:
            æŒ‡æ ‡å€¼ï¼ˆfloatï¼‰æˆ–None
        """
        for key in possible_keys:
            if key in metrics_dict:
                value = metrics_dict[key]

                # å¤„ç†tensorç±»å‹
                if isinstance(value, torch.Tensor):
                    return value.item()

                # å¤„ç†numpyç±»å‹
                elif hasattr(value, "item"):
                    return value.item()

                # å¤„ç†æ™®é€šæ•°å€¼
                elif isinstance(value, (int, float)):
                    return float(value)

                # å…¶ä»–ç±»å‹
                else:
                    logger.warning(f"Unknown metric type for {key}: {type(value)}")
                    return None

        return None

    def _update_best_metrics(self, current_metrics: Dict[str, Any], current_epoch: int):
        """æ›´æ–°æœ€ä½³æŒ‡æ ‡è·Ÿè¸ª"""
        val_f1 = current_metrics.get("val_f1")

        if val_f1 is not None:
            # æ›´æ–°æœ€ä½³F1
            if "best_val_f1" not in self.best_metrics or val_f1 > self.best_metrics["best_val_f1"]:
                self.best_metrics.update(
                    {
                        "best_val_f1": val_f1,
                        "best_val_f1_epoch": current_epoch,
                        "best_val_acc": current_metrics.get("val_acc"),
                        "best_val_auroc": current_metrics.get("val_auroc"),
                        "best_val_loss": current_metrics.get("val_loss"),
                        "best_timestamp": current_metrics.get("timestamp"),
                    }
                )

                logger.info(f"ğŸ‰ New best F1 score: {val_f1:.4f} at epoch {current_epoch}")

        # æ›´æ–°æœ€ä½³å‡†ç¡®ç‡ï¼ˆç‹¬ç«‹è·Ÿè¸ªï¼‰
        val_acc = current_metrics.get("val_acc")
        if val_acc is not None:
            if "best_val_acc" not in self.best_metrics or val_acc > self.best_metrics.get("best_val_acc_standalone", 0):
                self.best_metrics["best_val_acc_standalone"] = val_acc
                self.best_metrics["best_val_acc_epoch"] = current_epoch

    def _print_detailed_summary(self, trainer, current_metrics: Dict[str, Any]):
        """æ‰“å°è¯¦ç»†çš„è®­ç»ƒæ€»ç»“"""
        logger.info(f"\n{'='*100}")
        logger.info(f"ğŸ“Š Epoch {trainer.current_epoch} Detailed Summary")
        logger.info(f"{'='*100}")

        # å½“å‰æŒ‡æ ‡
        train_loss = current_metrics.get("train_loss")
        val_loss = current_metrics.get("val_loss")
        val_f1 = current_metrics.get("val_f1")
        val_acc = current_metrics.get("val_acc")
        val_auroc = current_metrics.get("val_auroc")
        lr = current_metrics.get("learning_rate")

        logger.info(f"Current Metrics:")
        logger.info(f"  Train Loss: {train_loss:.4f}" if train_loss is not None else "  Train Loss: N/A")
        logger.info(f"  Val Loss:   {val_loss:.4f}" if val_loss is not None else "  Val Loss: N/A")
        logger.info(f"  Val F1:     {val_f1:.4f}" if val_f1 is not None else "  Val F1: N/A")
        logger.info(f"  Val Acc:    {val_acc:.4f}" if val_acc is not None else "  Val Acc: N/A")
        logger.info(f"  Val AUROC:  {val_auroc:.4f}" if val_auroc is not None else "  Val AUROC: N/A")
        logger.info(f"  Learning Rate: {lr:.6f}" if lr is not None else "  Learning Rate: N/A")

        # æœ€ä½³æŒ‡æ ‡
        if self.best_metrics:
            logger.info(f"\nBest Metrics So Far:")
            logger.info(
                f"  Best Val F1: {self.best_metrics.get('best_val_f1', 'N/A'):.4f} "
                f"(Epoch {self.best_metrics.get('best_val_f1_epoch', 'N/A')})"
            )

            best_acc = self.best_metrics.get("best_val_acc_standalone")
            if best_acc is not None:
                logger.info(
                    f"  Best Val Acc: {best_acc:.4f} " f"(Epoch {self.best_metrics.get('best_val_acc_epoch', 'N/A')})"
                )

        # è®­ç»ƒæ•ˆç‡ç»Ÿè®¡
        if self.epoch_times:
            recent_times = self.epoch_times[-min(10, len(self.epoch_times)) :]
            avg_time = np.mean(recent_times)
            logger.info(f"\nTraining Efficiency:")
            logger.info(f"  Avg Epoch Time (last {len(recent_times)}): {avg_time:.2f}s")

            if len(self.epoch_times) > 1:
                total_time = sum(self.epoch_times)
                remaining_epochs = trainer.max_epochs - trainer.current_epoch - 1
                estimated_remaining = remaining_epochs * avg_time
                logger.info(f"  Estimated Remaining Time: {estimated_remaining/3600:.2f}h")

        logger.info(f"{'='*100}\n")

    def _print_final_summary(self, trainer, training_time: float):
        """æ‰“å°æœ€ç»ˆè®­ç»ƒæ€»ç»“"""
        logger.info(f"\n{'ğŸ¯'*50}")
        logger.info(f"ğŸ¯ TRAINING COMPLETED - FINAL SUMMARY")
        logger.info(f"{'ğŸ¯'*50}")

        logger.info(f"ğŸ“ˆ Training Statistics:")
        logger.info(f"  Total Epochs: {trainer.current_epoch + 1}")
        logger.info(f"  Total Training Time: {training_time/3600:.2f}h")

        if self.epoch_times:
            avg_epoch_time = np.mean(self.epoch_times)
            logger.info(f"  Average Epoch Time: {avg_epoch_time:.2f}s")

        # æœ€ä½³æ€§èƒ½
        if self.best_metrics:
            logger.info(f"\nğŸ† Best Performance Achieved:")
            best_f1 = self.best_metrics.get("best_val_f1")
            best_epoch = self.best_metrics.get("best_val_f1_epoch")

            if best_f1 is not None:
                logger.info(f"  ğŸ¥‡ Best F1 Score: {best_f1:.4f} at Epoch {best_epoch}")
                logger.info(f"     â”œâ”€ Validation Accuracy: {self.best_metrics.get('best_val_acc', 'N/A'):.4f}")
                logger.info(f"     â”œâ”€ Validation AUROC: {self.best_metrics.get('best_val_auroc', 'N/A'):.4f}")
                logger.info(f"     â””â”€ Validation Loss: {self.best_metrics.get('best_val_loss', 'N/A'):.4f}")

        logger.info(f"{'ğŸ¯'*50}\n")

    def _save_experiment_report(self, trainer, training_time: float):
        """ä¿å­˜å®Œæ•´çš„å®éªŒæŠ¥å‘Š"""
        try:
            # ç¡®å®šä¿å­˜ç›®å½•
            save_dir = self._get_save_directory()
            report_file = save_dir / "experiment_report.json"

            # æ„å»ºå®Œæ•´æŠ¥å‘Š
            report = {
                "experiment_info": {
                    "completed_at": datetime.now().isoformat(),
                    "total_epochs": trainer.current_epoch + 1,
                    "total_training_time_hours": training_time / 3600,
                    "average_epoch_time_seconds": np.mean(self.epoch_times) if self.epoch_times else 0,
                    "max_epochs_configured": trainer.max_epochs,
                },
                "best_metrics": self.best_metrics,
                "training_efficiency": {
                    "epoch_times": self.epoch_times,
                    "total_batches_processed": trainer.global_step,
                    "gpu_used": torch.cuda.is_available(),
                    "device_count": trainer.num_devices if hasattr(trainer, "num_devices") else 1,
                },
                "metrics_history": self.metrics_history if self.metrics_history else [],
                "model_info": {
                    "model_class": trainer.model.__class__.__name__,
                    "total_parameters": sum(p.numel() for p in trainer.model.parameters()),
                    "trainable_parameters": sum(p.numel() for p in trainer.model.parameters() if p.requires_grad),
                },
            }

            # ä¿å­˜æŠ¥å‘Š
            with open(report_file, "w") as f:
                json.dump(report, f, indent=2, default=str)

            logger.info(f"ğŸ“ Experiment report saved: {report_file}")

        except Exception as e:
            logger.error(f"Failed to save experiment report: {e}")

    def _get_save_directory(self) -> Path:
        """è·å–ä¿å­˜ç›®å½•"""
        if self.custom_log_dir:
            target_dir = self.custom_log_dir
        else:
            # ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ä½œä¸ºfallback
            target_dir = Path.cwd() / "logs"

        target_dir.mkdir(parents=True, exist_ok=True)
        return target_dir
