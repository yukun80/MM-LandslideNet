# =============================================================================
# lightning_landslide/src/models/optical_convnext.py - ConvNextv2åˆ†ç±»æ¨¡å‹
# =============================================================================

"""
åŸºäºConvNextv2çš„å…‰å­¦æ•°æ®æ¨¡å‹

è¿™ä¸ªæ¨¡å—æ˜¯OpticalSwinModelçš„"å…„å¼Ÿ"å®ç°ï¼Œéµå¾ªå®Œå…¨ç›¸åŒçš„æ¥å£è®¾è®¡ï¼Œ
è®©ç”¨æˆ·å¯ä»¥é€šè¿‡ç®€å•ä¿®æ”¹é…ç½®æ–‡ä»¶å°±èƒ½åœ¨Swin Transformerå’ŒConvNextv2ä¹‹é—´åˆ‡æ¢ã€‚

æ ¸å¿ƒç‰¹æ€§ï¼š
1. å¤„ç†5é€šé“è¾“å…¥ï¼šR, G, B, NIR, NDVI
2. åŠ¨æ€ä¸Šé‡‡æ ·ï¼šä»64x64è‡ªé€‚åº”åˆ°ç›®æ ‡å°ºå¯¸
3. ç‰¹å¾åˆ†ç¦»ï¼šåˆ†ç¦»ç‰¹å¾æå–å’Œåˆ†ç±»å†³ç­–
4. æ™ºèƒ½æƒé‡åˆå§‹åŒ–ï¼šå……åˆ†åˆ©ç”¨é¢„è®­ç»ƒæƒé‡

è®¾è®¡å“²å­¦ï¼š
- æ¥å£ä¸€è‡´æ€§ï¼šä¸OpticalSwinModelæä¾›ç›¸åŒçš„æ¥å£
- é…ç½®é©±åŠ¨ï¼šé€šè¿‡é…ç½®æ–‡ä»¶æ§åˆ¶æ‰€æœ‰è¡Œä¸º
- å³æ’å³ç”¨ï¼šå¯ä»¥æ— ç¼æ›¿æ¢ç°æœ‰çš„Swinæ¨¡å‹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
import logging
from typing import Dict, Any, Optional, List, Tuple
from omegaconf import DictConfig
from pathlib import Path

from .base import BaseModel

logger = logging.getLogger(__name__)


class OpticalConvNextModel(BaseModel):
    """
    åŸºäºConvNextv2çš„å…‰å­¦æ•°æ®æ¨¡å‹

    ConvNextv2ç›¸æ¯”Swin Transformerçš„ä¼˜åŠ¿ï¼š
    1. æ›´ç®€å•çš„æ¶æ„ï¼Œè®­ç»ƒæ›´ç¨³å®š
    2. æ›´å¥½çš„å°ºåº¦ä¸å˜æ€§
    3. åœ¨æŸäº›ä»»åŠ¡ä¸Šç²¾åº¦æ›´é«˜
    4. æ¨ç†é€Ÿåº¦é€šå¸¸æ›´å¿«

    æ ¸å¿ƒåŠŸèƒ½ä¸OpticalSwinModelå®Œå…¨ä¸€è‡´ï¼š
    - 5é€šé“è¾“å…¥å¤„ç†
    - åŠ¨æ€å°ºå¯¸é€‚é…
    - é¢„è®­ç»ƒæƒé‡æ™ºèƒ½åˆå§‹åŒ–
    """

    def __init__(
        self,
        model_name: str = "convnextv2_tiny.fcmae_ft_in22k_in1k",
        input_channels: int = 5,
        pretrained: bool = True,
        dropout_rate: float = 0.2,
        pretrained_path: Optional[str] = None,
        img_size: int = 256,
    ):
        super().__init__()

        # ä¿å­˜é…ç½®ä¿¡æ¯
        self.model_name = model_name
        self.input_channels = input_channels
        self.pretrained = pretrained
        self.dropout_rate = dropout_rate
        self.img_size = img_size

        logger.info(f"Initializing OpticalConvNextModel with {model_name}")
        logger.info(f"Target image size: {self.img_size}x{self.img_size}")

        # æœ¬åœ°æƒé‡ä¼˜å…ˆçº§å¤„ç†
        use_timm_pretrained = pretrained and (pretrained_path is None)

        # åˆ›å»ºConvNextv2éª¨å¹²ç½‘ç»œ
        self.backbone = timm.create_model(
            model_name,
            pretrained=use_timm_pretrained,
            num_classes=0,  # ç§»é™¤åˆ†ç±»å¤´ï¼Œåªè¦ç‰¹å¾æå–
            global_pool="avg",  # å…¨å±€å¹³å‡æ± åŒ–
        )

        # åŠ è½½æœ¬åœ°æƒé‡ï¼ˆå¦‚æœæä¾›ï¼‰
        if pretrained_path:
            self._load_local_weights(pretrained_path)

        # è·å–ç‰¹å¾ç»´åº¦
        self.feature_dim = self.backbone.num_features
        logger.info(f"Backbone feature dimension: {self.feature_dim}")

        # ä¿®æ”¹è¾“å…¥å±‚ä»¥æ”¯æŒ5é€šé“
        self._modify_input_layer()

        # ä¿å­˜æ¨¡å‹ä¿¡æ¯
        self._model_info.update(
            {
                "backbone_name": model_name,
                "input_channels": input_channels,
                "pretrained": pretrained,
                "pretrained_path": pretrained_path,
                "dropout_rate": dropout_rate,
                "img_size": img_size,
            }
        )

        logger.info("ğŸš€ OpticalConvNextModel initialization completed successfully")

    def _load_local_weights(self, pretrained_path: str):
        """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½é¢„è®­ç»ƒæƒé‡"""
        path = Path(pretrained_path)
        if not path.is_file():
            raise FileNotFoundError(f"Pretrained weights file not found at: {pretrained_path}")

        try:
            state_dict = torch.load(pretrained_path, map_location="cpu")

            # å¤„ç†ä¸åŒæ ¼å¼çš„æƒé‡æ–‡ä»¶
            if "model" in state_dict:
                state_dict = state_dict["model"]
            elif "state_dict" in state_dict:
                state_dict = state_dict["state_dict"]

            # åŠ è½½æƒé‡
            result = self.backbone.load_state_dict(state_dict, strict=False)
            logger.info(f"Local weight loading result: {result}")

            # è®°å½•æœªåŒ¹é…çš„é”®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if result.missing_keys:
                logger.warning(f"Missing keys: {result.missing_keys[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª
            if result.unexpected_keys:
                logger.warning(f"Unexpected keys: {result.unexpected_keys[:5]}...")

        except Exception as e:
            logger.error(f"Failed to load local weights from {pretrained_path}: {e}")
            raise

    def _modify_input_layer(self) -> None:
        """
        ä¿®æ”¹è¾“å…¥å±‚ä»¥å¤„ç†5é€šé“è¾“å…¥

        ConvNextv2çš„è¾“å…¥å±‚é€šå¸¸æ˜¯stemæ¨¡å—ä¸­çš„ç¬¬ä¸€ä¸ªå·ç§¯å±‚ã€‚
        æˆ‘ä»¬éœ€è¦å°†å…¶ä»3é€šé“æ‰©å±•åˆ°5é€šé“ï¼Œå¹¶æ™ºèƒ½åœ°åˆå§‹åŒ–æ–°å¢é€šé“çš„æƒé‡ã€‚

        ç­–ç•¥ï¼š
        1. æ‰¾åˆ°ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        2. åˆ›å»ºæ–°çš„5é€šé“å·ç§¯å±‚
        3. æ™ºèƒ½å¤åˆ¶å’Œåˆå§‹åŒ–æƒé‡
        4. æ›¿æ¢åŸæœ‰å±‚
        """
        if self.input_channels == 3:
            logger.info("Input channels is 3, no modification needed")
            return

        # å¯»æ‰¾ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        first_conv_name, first_conv, old_weight = self._find_first_conv()
        if first_conv is None:
            raise RuntimeError("Cannot find the first convolutional layer")

        logger.info(f"Found first conv layer: {first_conv_name}")
        logger.info(f"Original weight shape: {old_weight.shape}")

        # åˆ›å»ºæ–°çš„å·ç§¯å±‚
        new_conv = nn.Conv2d(
            in_channels=self.input_channels,
            out_channels=first_conv.out_channels,
            kernel_size=first_conv.kernel_size,
            stride=first_conv.stride,
            padding=first_conv.padding,
            bias=first_conv.bias is not None,
        )

        # æ™ºèƒ½åˆå§‹åŒ–æƒé‡
        with torch.no_grad():
            if old_weight.shape[1] == 3:  # é¢„è®­ç»ƒæƒé‡æ˜¯3é€šé“
                # å‰3ä¸ªé€šé“ç›´æ¥å¤åˆ¶RGBæƒé‡
                new_conv.weight[:, :3, :, :] = old_weight

                # NIRé€šé“ï¼šä½¿ç”¨çº¢å…‰é€šé“çš„æƒé‡ï¼ˆç›¸è¿‘æ³¢æ®µï¼‰
                new_conv.weight[:, 3:4, :, :] = old_weight[:, 0:1, :, :] * 0.8  # è½»å¾®è¡°å‡

                # NDVIé€šé“ï¼šç»“åˆçº¢å…‰å’Œè¿‘çº¢å¤–çš„ç‰¹å¾
                if self.input_channels >= 5:
                    red_weight = old_weight[:, 0:1, :, :]  # Ré€šé“
                    nir_weight = old_weight[:, 0:1, :, :] * 0.8  # æ¨¡æ‹ŸNIR
                    # NDVIé€šå¸¸æ˜¯(NIR-R)/(NIR+R)çš„å˜åŒ–ï¼Œè¿™é‡Œç®€åŒ–ä¸ºå·®å¼‚
                    new_conv.weight[:, 4:5, :, :] = (nir_weight - red_weight) * 0.5

                # å¦‚æœæœ‰æ›´å¤šé€šé“ï¼Œä½¿ç”¨NIRçš„æ¨¡å¼
                for i in range(5, self.input_channels):
                    new_conv.weight[:, i : i + 1, :, :] = new_conv.weight[:, 3:4, :, :]

                logger.info("âœ“ Successfully initialized 5-channel weights from 3-channel pretrained weights")

            else:
                # å¦‚æœé¢„è®­ç»ƒæƒé‡ä¸æ˜¯3é€šé“ï¼Œä½¿ç”¨æ ‡å‡†åˆå§‹åŒ–
                nn.init.kaiming_normal_(new_conv.weight, mode="fan_out", nonlinearity="relu")
                logger.warning(f"Unexpected pretrained weight channels: {old_weight.shape[1]}, using random init")

            # å¤åˆ¶bias
            if new_conv.bias is not None and first_conv.bias is not None:
                new_conv.bias.data = first_conv.bias.data.clone()

        # æ›¿æ¢åŸæœ‰å±‚
        self._replace_layer(first_conv_name, new_conv)
        logger.info(f"âœ“ Successfully replaced input layer: {first_conv_name}")

    def _find_first_conv(self) -> Tuple[str, Optional[nn.Conv2d], Optional[torch.Tensor]]:
        """
        å¯»æ‰¾ç¬¬ä¸€ä¸ªå·ç§¯å±‚

        ConvNextv2çš„æ¶æ„ä¸­ï¼Œç¬¬ä¸€ä¸ªå·ç§¯å±‚é€šå¸¸åœ¨ï¼š
        - stem.0 æˆ– stem.conv
        - downsample_layers.0.0 æˆ–ç±»ä¼¼è·¯å¾„

        Returns:
            (layer_name, conv_layer, weight_tensor)
        """
        # å¸¸è§çš„ç¬¬ä¸€å±‚è·¯å¾„æ¨¡å¼
        common_paths = [
            "stem.0",
            "stem.conv",
            "downsample_layers.0.0",
            "downsample_layers.0.conv",
            "features.0",
            "features.stem.0",
        ]

        # é¦–å…ˆå°è¯•å¸¸è§è·¯å¾„
        for path in common_paths:
            layer = self._get_layer_by_path(path)
            if isinstance(layer, nn.Conv2d):
                return path, layer, layer.weight.data

        # å¦‚æœå¸¸è§è·¯å¾„æ‰¾ä¸åˆ°ï¼Œéå†æ‰€æœ‰æ¨¡å—
        for name, module in self.backbone.named_modules():
            if isinstance(module, nn.Conv2d):
                logger.info(f"Found first conv layer through traversal: {name}")
                return name, module, module.weight.data

        return None, None, None

    def _get_layer_by_path(self, path: str) -> Optional[nn.Module]:
        """é€šè¿‡è·¯å¾„è·å–å±‚"""
        try:
            current = self.backbone
            for part in path.split("."):
                if part.isdigit():
                    current = current[int(part)]
                else:
                    current = getattr(current, part)
            return current
        except (AttributeError, IndexError, KeyError):
            return None

    def _replace_layer(self, layer_name: str, new_layer: nn.Module) -> None:
        """
        æ›¿æ¢æŒ‡å®šåç§°çš„å±‚

        æ”¯æŒåµŒå¥—è·¯å¾„ï¼Œå¦‚ "stem.0" æˆ– "downsample_layers.0.0"
        """
        parts = layer_name.split(".")
        current = self.backbone

        # å¯¼èˆªåˆ°çˆ¶æ¨¡å—
        for part in parts[:-1]:
            if part.isdigit():
                current = current[int(part)]
            else:
                current = getattr(current, part)

        # æ›¿æ¢ç›®æ ‡å±‚
        final_part = parts[-1]
        if final_part.isdigit():
            current[int(final_part)] = new_layer
        else:
            setattr(current, final_part, new_layer)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­

        å¤„ç†æµç¨‹ï¼š
        1. éªŒè¯è¾“å…¥ç»´åº¦
        2. åŠ¨æ€ä¸Šé‡‡æ ·åˆ°ç›®æ ‡å°ºå¯¸
        3. é€šè¿‡éª¨å¹²ç½‘ç»œæå–ç‰¹å¾
        """
        # è¾“å…¥éªŒè¯
        if x.dim() != 4:
            raise ValueError(f"Expected 4D input (batch, channel, height, width), got {x.dim()}D")

        if x.size(1) != self.input_channels:
            raise ValueError(f"Expected {self.input_channels} input channels, got {x.size(1)}")

        # åŠ¨æ€ä¸Šé‡‡æ ·
        if x.shape[-1] != self.img_size:
            x = F.interpolate(x, size=(self.img_size, self.img_size), mode="bilinear", align_corners=False)

        # ç‰¹å¾æå–
        features = self.backbone(x)
        return features

    def get_feature_dim(self) -> int:
        """
        è¿”å›ç‰¹å¾ç»´åº¦

        ConvNextv2çš„ä¸åŒå˜ä½“æœ‰ä¸åŒçš„ç‰¹å¾ç»´åº¦ï¼š
        - tiny: 768
        - small: 768
        - base: 1024
        - large: 1536
        """
        return self.feature_dim

    def get_features_with_intermediate(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        è·å–ä¸­é—´å±‚ç‰¹å¾ï¼ˆç”¨äºå¯è§†åŒ–å’Œåˆ†æï¼‰

        ConvNextv2æ˜¯åˆ†é˜¶æ®µçš„æ¶æ„ï¼Œæˆ‘ä»¬å¯ä»¥æå–æ¯ä¸ªé˜¶æ®µçš„ç‰¹å¾ã€‚
        """
        features = {}

        # è¾“å…¥å¤„ç†
        if x.shape[-1] != self.img_size:
            x = F.interpolate(x, size=(self.img_size, self.img_size), mode="bilinear", align_corners=False)

        # å°è¯•æå–å„é˜¶æ®µç‰¹å¾
        current = x
        stage_names = ["stem", "stage1", "stage2", "stage3", "stage4"]

        try:
            # Stemå¤„ç†
            if hasattr(self.backbone, "stem"):
                current = self.backbone.stem(current)
                features["stem"] = current
            elif hasattr(self.backbone, "downsample_layers"):
                current = self.backbone.downsample_layers[0](current)
                features["stem"] = current

            # å„ä¸ªstage
            if hasattr(self.backbone, "stages"):
                for i, stage in enumerate(self.backbone.stages):
                    current = stage(current)
                    features[f"stage_{i+1}"] = current

            # æœ€ç»ˆç‰¹å¾
            if hasattr(self.backbone, "norm"):
                current = self.backbone.norm(current)
            if hasattr(self.backbone, "head"):
                if hasattr(self.backbone.head, "global_pool"):
                    current = self.backbone.head.global_pool(current)
                    current = current.flatten(1)

            features["final"] = current

        except Exception as e:
            logger.warning(f"Failed to extract intermediate features: {e}")
            # å›é€€åˆ°å®Œæ•´å‰å‘ä¼ æ’­
            features["final"] = self.backbone(x)

        return features

    @classmethod
    def from_config(cls, cfg: DictConfig) -> "OpticalConvNextModel":
        """
        ä»é…ç½®åˆ›å»ºæ¨¡å‹å®ä¾‹

        æ”¯æŒçš„é…ç½®å‚æ•°ï¼š
        - model_name: ConvNextv2å˜ä½“åç§°
        - input_channels: è¾“å…¥é€šé“æ•°
        - pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        - dropout_rate: dropoutæ¯”ç‡
        - pretrained_path: æœ¬åœ°æƒé‡è·¯å¾„
        - img_size: ç›®æ ‡å›¾åƒå°ºå¯¸
        """
        # ä»é…ç½®ä¸­æå–å‚æ•°ï¼Œæä¾›åˆç†çš„é»˜è®¤å€¼
        return cls(
            model_name=cfg.get("model_name", "convnextv2_tiny.fcmae_ft_in22k_in1k"),
            input_channels=cfg.get("input_channels", 5),
            pretrained=cfg.get("pretrained", True),
            dropout_rate=cfg.get("dropout_rate", 0.2),
            pretrained_path=cfg.get("pretrained_path", None),
            img_size=cfg.get("img_size", 256),
        )

    def freeze_stem(self) -> None:
        """
        åªå†»ç»“stemå±‚

        åœ¨æŸäº›è¿ç§»å­¦ä¹ åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½åªæƒ³å†»ç»“è¾“å…¥å¤„ç†éƒ¨åˆ†ï¼Œ
        è€Œè®©åç»­çš„ç‰¹å¾å­¦ä¹ å±‚ç»§ç»­è®­ç»ƒã€‚
        """
        if hasattr(self.backbone, "stem"):
            for param in self.backbone.stem.parameters():
                param.requires_grad = False
            logger.info("Frozen stem layers")
        elif hasattr(self.backbone, "downsample_layers"):
            for param in self.backbone.downsample_layers[0].parameters():
                param.requires_grad = False
            logger.info("Frozen first downsample layer (stem equivalent)")

    def unfreeze_last_stages(self, num_stages: int = 2) -> None:
        """
        è§£å†»æœ€åå‡ ä¸ªstage

        è¿™æ˜¯ä¸€ç§å¸¸è§çš„æ¸è¿›è§£å†»ç­–ç•¥ï¼šå…ˆè®­ç»ƒåˆ†ç±»å¤´ï¼Œ
        ç„¶åé€æ­¥è§£å†»æ›´å¤šçš„å±‚ã€‚

        Args:
            num_stages: è¦è§£å†»çš„æœ€åå‡ ä¸ªstageæ•°é‡
        """
        if hasattr(self.backbone, "stages"):
            total_stages = len(self.backbone.stages)
            start_stage = max(0, total_stages - num_stages)

            for i in range(start_stage, total_stages):
                for param in self.backbone.stages[i].parameters():
                    param.requires_grad = True

            logger.info(f"Unfroze last {num_stages} stages (stages {start_stage}-{total_stages-1})")

    def get_trainable_parameters(self) -> List[Dict[str, Any]]:
        """
        è·å–åˆ†å±‚çš„è®­ç»ƒå‚æ•°ç»„

        ConvNextv2å¯ä»¥ä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡ï¼š
        - stem: æœ€å°å­¦ä¹ ç‡
        - early stages: è¾ƒå°å­¦ä¹ ç‡
        - later stages: è¾ƒå¤§å­¦ä¹ ç‡
        - classifier: æœ€å¤§å­¦ä¹ ç‡ï¼ˆç”±å¤–éƒ¨åˆ†ç±»å¤´ç®¡ç†ï¼‰
        """
        param_groups = []
        base_lr = 1e-4  # è¿™ä¼šè¢«ä¼˜åŒ–å™¨é…ç½®è¦†ç›–

        # Stemå‚æ•°ç»„
        stem_params = []
        if hasattr(self.backbone, "stem"):
            stem_params.extend(self.backbone.stem.parameters())
        elif hasattr(self.backbone, "downsample_layers"):
            stem_params.extend(self.backbone.downsample_layers[0].parameters())

        if stem_params:
            param_groups.append({"params": stem_params, "lr": base_lr * 0.1, "name": "stem"})

        # Stageå‚æ•°ç»„
        if hasattr(self.backbone, "stages"):
            num_stages = len(self.backbone.stages)
            for i, stage in enumerate(self.backbone.stages):
                # åé¢çš„stageä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡
                lr_multiplier = 0.2 + 0.6 * (i / max(1, num_stages - 1))
                param_groups.append(
                    {"params": list(stage.parameters()), "lr": base_lr * lr_multiplier, "name": f"stage_{i}"}
                )

        # å…¶ä»–å‚æ•°ï¼ˆnormç­‰ï¼‰
        handled_params = set()
        for group in param_groups:
            handled_params.update(id(p) for p in group["params"])

        remaining_params = []
        for param in self.parameters():
            if id(param) not in handled_params:
                remaining_params.append(param)

        if remaining_params:
            param_groups.append({"params": remaining_params, "lr": base_lr, "name": "others"})

        logger.info(f"Created {len(param_groups)} parameter groups with layered learning rates")
        return param_groups


# ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºä¸åŒå˜ä½“çš„ConvNextv2æ¨¡å‹
def create_convnext_tiny(
    input_channels: int = 5, pretrained: bool = True, dropout_rate: float = 0.2
) -> OpticalConvNextModel:
    """åˆ›å»ºConvNextv2 Tinyæ¨¡å‹"""
    return OpticalConvNextModel(
        model_name="convnextv2_tiny.fcmae_ft_in22k_in1k",
        input_channels=input_channels,
        pretrained=pretrained,
        dropout_rate=dropout_rate,
    )


def create_convnext_small(
    input_channels: int = 5, pretrained: bool = True, dropout_rate: float = 0.2
) -> OpticalConvNextModel:
    """åˆ›å»ºConvNextv2 Smallæ¨¡å‹"""
    return OpticalConvNextModel(
        model_name="convnextv2_small.fcmae_ft_in22k_in1k",
        input_channels=input_channels,
        pretrained=pretrained,
        dropout_rate=dropout_rate,
    )


def create_convnext_base(
    input_channels: int = 5, pretrained: bool = True, dropout_rate: float = 0.2
) -> OpticalConvNextModel:
    """åˆ›å»ºConvNextv2 Baseæ¨¡å‹"""
    return OpticalConvNextModel(
        model_name="convnextv2_base.fcmae_ft_in22k_in1k",
        input_channels=input_channels,
        pretrained=pretrained,
        dropout_rate=dropout_rate,
    )


# æµ‹è¯•åŠŸèƒ½
def test_optical_convnext_model():
    """æµ‹è¯•æ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½"""
    print("Testing OpticalConvNextModel...")

    # åˆ›å»ºæ¨¡å‹
    model = create_convnext_tiny()
    model.eval()

    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 2
    test_input = torch.randn(batch_size, 5, 64, 64)

    # å‰å‘ä¼ æ’­æµ‹è¯•
    with torch.no_grad():
        features = model(test_input)
        print(f"Input shape: {test_input.shape}")
        print(f"Output features shape: {features.shape}")
        print(f"Feature dimension: {model.get_feature_dim()}")

    # æ¨¡å‹ä¿¡æ¯æµ‹è¯•
    model.summary()

    print("âœ“ OpticalConvNextModel test passed!")


if __name__ == "__main__":
    test_optical_convnext_model()
