import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
import logging
from typing import Dict, Any, Optional, List, Tuple
from omegaconf import DictConfig
from pathlib import Path

from .base import BaseModel

"""
python -m lightning_landslide.src.models.optical_swin
torchç‰ˆæœ¬æ¨¡å‹æ„å»º
"""

logger = logging.getLogger(__name__)  # æ—¥å¿—è®°å½•å™¨, __name__ æ˜¯æ¨¡å—å


class OpticalSwinModel(BaseModel):
    """
    åŸºäºSwin Transformerçš„å…‰å­¦æ•°æ®æ¨¡å‹

    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. å¤„ç†5é€šé“è¾“å…¥ï¼šR, G, B, NIR, NDVI
    2. åŠ¨æ€ä¸Šé‡‡æ ·ï¼šä»64x64è‡ªé€‚åº”åˆ°224x224
    3. ç‰¹å¾åˆ†ç¦»ï¼šåˆ†ç¦»ç‰¹å¾æå–å’Œåˆ†ç±»å†³ç­–
    """

    def __init__(
        self,
        model_name: str = "swinv2_small_window16_256",
        input_channels: int = 5,
        pretrained: bool = True,
        dropout_rate: float = 0.2,
        pretrained_path: Optional[str] = None,  # æ–°å¢ï¼šæœ¬åœ°æƒé‡è·¯å¾„
        img_size: int = 256,  # æ–°å¢ï¼šå›¾åƒå°ºå¯¸
    ):
        super().__init__()

        # ä¿å­˜é…ç½®ä¿¡æ¯
        self.model_name = model_name
        self.input_channels = input_channels
        self.pretrained = pretrained
        self.dropout_rate = dropout_rate
        self.img_size = img_size  # ä¿å­˜å›¾åƒå°ºå¯¸

        logger.info(f"Initializing OpticalSwinModel with {model_name}")
        logger.info(f"Target image size: {self.img_size}x{self.img_size}")

        # å¦‚æœæä¾›äº†æœ¬åœ°è·¯å¾„ï¼Œåˆ™ä¸ä½¿ç”¨timmçš„åœ¨çº¿é¢„è®­ç»ƒ
        use_timm_pretrained = pretrained and (pretrained_path is None)

        # åˆ›å»ºSwin Transformeréª¨å¹²ç½‘ç»œ
        self.backbone = timm.create_model(
            model_name,
            pretrained=use_timm_pretrained,
            num_classes=0,
            global_pool="avg",
        )

        # å¦‚æœæä¾›äº†æœ¬åœ°è·¯å¾„ï¼ŒåŠ è½½æœ¬åœ°æƒé‡
        if pretrained_path:
            self._load_local_weights(pretrained_path)

        self.feature_dim = self.backbone.num_features
        logger.info(f"Backbone feature dimension: {self.feature_dim}")

        self._modify_input_layer()

        self._model_info.update(
            {
                "backbone_name": model_name,
                "input_channels": input_channels,
                "pretrained": pretrained,
                "pretrained_path": pretrained_path,
                "dropout_rate": dropout_rate,
                "img_size": img_size,
            }
        )

        logger.info("ğŸ™OpticalSwinModel initialization completed successfully")

    def _load_local_weights(self, pretrained_path: str):
        """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½é¢„è®­ç»ƒæƒé‡"""
        path = Path(pretrained_path)
        if not path.is_file():
            raise FileNotFoundError(f"Pretrained weights file not found at: {pretrained_path}")

        try:
            state_dict = torch.load(pretrained_path, map_location="cpu")

            # timmçš„æƒé‡é€šå¸¸åœ¨'model'é”®ä¸‹
            if "model" in state_dict:
                state_dict = state_dict["model"]

            # åŠ è½½æƒé‡
            result = self.backbone.load_state_dict(state_dict, strict=False)
            logger.info(f"Weight loading result: {result}")

            # æ£€æŸ¥æ˜¯å¦æœ‰æœªåŠ è½½çš„é”®ï¼Œè¿™å¯¹äºè°ƒè¯•éå¸¸é‡è¦
            if result.missing_keys:
                logger.warning(f"Missing keys: {result.missing_keys}")
            if result.unexpected_keys:
                logger.warning(f"Unexpected keys: {result.unexpected_keys}")

        except Exception as e:
            logger.error(f"Failed to load local weights from {pretrained_path}: {e}")
            raise

    def _modify_input_layer(self) -> None:
        """
        ä¿®æ”¹è¾“å…¥å±‚ä»¥å¤„ç†5é€šé“è¾“å…¥

        è¿™æ˜¯æ‚¨åŸæœ‰å®ç°ä¸­æœ€ç²¾å½©çš„éƒ¨åˆ†ã€‚æˆ‘ä»¬ä¸ä»…è¦æ”¯æŒ5é€šé“è¾“å…¥ï¼Œ
        è¿˜è¦æ™ºèƒ½åœ°åˆå§‹åŒ–æƒé‡ï¼Œå……åˆ†åˆ©ç”¨é¢„è®­ç»ƒçš„RGBæƒé‡ã€‚

        ç­–ç•¥åˆ†è§£ï¼š
        1. æ‰¾åˆ°ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        2. åˆ›å»ºæ–°çš„5é€šé“å·ç§¯å±‚
        3. æ™ºèƒ½å¤åˆ¶é¢„è®­ç»ƒæƒé‡ï¼š
           - å‰3é€šé“ï¼šç›´æ¥å¤åˆ¶RGBæƒé‡
           - ç¬¬4é€šé“(NIR)ï¼šä½¿ç”¨RGBæƒé‡çš„å¹³å‡å€¼
           - ç¬¬5é€šé“(NDVI)ï¼šä½¿ç”¨Redå’ŒNIRçš„ç»„åˆ
        4. æ›¿æ¢åŸæœ‰çš„å·ç§¯å±‚

        ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ
        è¿™ç§åˆå§‹åŒ–ç­–ç•¥è®©æ¨¡å‹åœ¨è®­ç»ƒå¼€å§‹æ—¶å°±å…·æœ‰è‰¯å¥½çš„ç‰¹å¾æå–èƒ½åŠ›ï¼Œ
        è€Œä¸æ˜¯ä»éšæœºæƒé‡å¼€å§‹ã€‚è¿™å¯¹äºé¥æ„Ÿæ•°æ®ç‰¹åˆ«æœ‰æ•ˆã€‚
        """
        logger.info(f"Modifying input layer for {self.input_channels}-channel input...")

        # æ­¥éª¤1ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        first_conv = None
        first_conv_name = ""

        # éå†æ‰€æœ‰æ¨¡å—ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªConv2då±‚
        for name, module in self.backbone.named_modules():
            if isinstance(module, nn.Conv2d):
                first_conv = module
                first_conv_name = name
                logger.info(f"Found first conv layer: {name}, shape: {module.weight.shape}")
                break

        if first_conv is None:
            raise RuntimeError(f"Could not find first convolution layer in {self.model_name}")

        # æ­¥éª¤2ï¼šåˆ›å»ºæ–°çš„5é€šé“å·ç§¯å±‚
        new_conv = nn.Conv2d(
            in_channels=self.input_channels,  # è¾“å…¥é€šé“æ•°
            out_channels=first_conv.out_channels,  # è¾“å‡ºé€šé“æ•°
            kernel_size=first_conv.kernel_size,  # å·ç§¯æ ¸å¤§å°
            stride=first_conv.stride,  # æ­¥é•¿
            padding=first_conv.padding,  # å¡«å……
            dilation=first_conv.dilation,  # è†¨èƒ€
            groups=first_conv.groups,  # åˆ†ç»„å·ç§¯
            bias=first_conv.bias is not None,  # æ˜¯å¦ä½¿ç”¨åç½®
            padding_mode=first_conv.padding_mode,  # å¡«å……æ¨¡å¼
        )

        # æ­¥éª¤3ï¼šæ™ºèƒ½æƒé‡åˆå§‹åŒ–
        with torch.no_grad():
            old_weight = first_conv.weight
            # weightæ˜¯å·ç§¯æ ¸çš„æƒé‡ï¼Œå½¢çŠ¶: (out_channels, in_channels, kernel_h, kernel_w)

            try:
                assert old_weight.shape[1] == 3  # ç¡®è®¤åŸå§‹æƒé‡æ˜¯3é€šé“
                # å‰3é€šé“ï¼šç›´æ¥å¤åˆ¶RGBé¢„è®­ç»ƒæƒé‡
                new_conv.weight[:, :3, :, :] = old_weight
                # ç¬¬4é€šé“(NIR)ï¼šä½¿ç”¨RGBæƒé‡çš„å¹³å‡å€¼ä½œä¸ºåˆå§‹åŒ–
                # è¿™åŸºäºå‡è®¾ï¼šNIRä¸å¯è§å…‰æœ‰ç›¸ä¼¼ä½†ä¸åŒçš„ç‰¹å¾æ¨¡å¼
                nir_init = old_weight.mean(dim=1, keepdim=True)  # å¯¹RGBé€šé“æ±‚å¹³å‡
                new_conv.weight[:, 3:4, :, :] = nir_init
                # logger.info("âœ“ Initialized NIR channel with RGB average")

                # ç¬¬5é€šé“(NDVI)ï¼šä½¿ç”¨Red+NIRçš„ç»„åˆè¿›è¡Œåˆå§‹åŒ–
                # è¿™åŸºäºNDVIè®¡ç®—å…¬å¼ï¼š(NIR-Red)/(NIR+Red)çš„ç‰¹å¾æ¨¡å¼
                if self.input_channels >= 5:
                    red_weight = old_weight[:, 0:1, :, :]  # Redé€šé“æƒé‡
                    ndvi_init = (nir_init + red_weight) / 2  # Redå’ŒNIRçš„å¹³å‡
                    new_conv.weight[:, 4:5, :, :] = ndvi_init
                    # logger.info("âœ“ Initialized NDVI channel with Red+NIR combination")

                # å¦‚æœæœ‰æ›´å¤šé€šé“ï¼Œä½¿ç”¨ç›¸åŒç­–ç•¥
                for i in range(5, self.input_channels):
                    new_conv.weight[:, i : i + 1, :, :] = nir_init
                    logger.info(f"âœ“ Initialized channel {i} with NIR pattern")
            except AssertionError:
                logger.warning(f"Unexpected pretrained weight channels: {old_weight.shape[1]}")
                nn.init.kaiming_normal_(new_conv.weight, mode="fan_out", nonlinearity="relu")

            # å¤åˆ¶biasï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if new_conv.bias is not None and first_conv.bias is not None:
                new_conv.bias.data = first_conv.bias.data.clone()

        # æ­¥éª¤4ï¼šæ›¿æ¢åŸæœ‰å·ç§¯å±‚
        self._replace_layer(first_conv_name, new_conv)
        logger.info(f"âœ“ Successfully replaced input layer: {first_conv_name}")

    def _replace_layer(self, layer_name: str, new_layer: nn.Module) -> None:
        """
        æ›¿æ¢æŒ‡å®šåç§°çš„å±‚

        è¿™ä¸ªæ–¹æ³•é€šè¿‡å±‚çš„å…¨é™å®šåç§°æ¥å®šä½å’Œæ›¿æ¢å±‚ã€‚
        ä¾‹å¦‚ï¼Œå¦‚æœå±‚åæ˜¯"patch_embed.proj"ï¼Œåˆ™éœ€è¦ï¼š
        1. è·å–patch_embedæ¨¡å—
        2. å°†å…¶projå±æ€§æ›¿æ¢ä¸ºæ–°å±‚

        Args:
            layer_name: å±‚çš„å…¨é™å®šåç§°ï¼Œå¦‚"patch_embed.proj"
            new_layer: æ–°çš„å±‚æ¨¡å—
        """
        # å°†å±‚åæŒ‰ç‚¹åˆ†å‰²ï¼š["patch_embed", "proj"]
        names = layer_name.split(".")

        # ä»backboneå¼€å§‹ï¼Œé€å±‚æ·±å…¥åˆ°ç›®æ ‡å±‚çš„çˆ¶æ¨¡å—
        current_module = self.backbone
        for name in names[:-1]:
            current_module = getattr(current_module, name)

        # æ›¿æ¢æœ€åä¸€çº§çš„å±æ€§
        final_name = names[-1]
        setattr(current_module, final_name, new_layer)

        # logger.info(f"Replaced layer: {layer_name}")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­

        è¿™ä¸ªæ–¹æ³•ç°åœ¨ä½¿ç”¨åœ¨åˆå§‹åŒ–æ—¶å®šä¹‰çš„ self.img_size
        æ¥è¿›è¡ŒåŠ¨æ€ä¸Šé‡‡æ ·ã€‚
        """
        if x.dim() != 4:
            raise ValueError(f"Expected 4D input (batch, channel, height, width), got {x.dim()}D")

        if x.size(1) != self.input_channels:
            raise ValueError(f"Expected {self.input_channels} input channels, got {x.size(1)}")

        # ä½¿ç”¨ self.img_size è¿›è¡ŒåŠ¨æ€ä¸Šé‡‡æ ·
        target_size = self.img_size
        if x.shape[-1] != target_size:
            x = F.interpolate(x, size=(target_size, target_size), mode="bilinear", align_corners=False)

        features = self.backbone(x)
        return features

    def get_feature_dim(self) -> int:
        """
        è¿”å›ç‰¹å¾ç»´åº¦

        è¿™ä¸ªä¿¡æ¯ç”¨äºæ„å»ºåˆé€‚çš„åˆ†ç±»å¤´ã€‚
        å¯¹äºswin_tinyï¼Œé€šå¸¸æ˜¯768ç»´ã€‚

        Returns:
            ç‰¹å¾ç»´åº¦
        """
        return self.feature_dim

    def get_features_with_intermediate(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        è·å–ä¸­é—´å±‚ç‰¹å¾ï¼ˆç”¨äºå¯è§†åŒ–å’Œåˆ†æï¼‰

        è¿™ä¸ªæ–¹æ³•æä¾›äº†æ›´è¯¦ç»†çš„ç‰¹å¾ä¿¡æ¯ï¼Œå¯ç”¨äºï¼š
        1. ç‰¹å¾å¯è§†åŒ–
        2. æ¨¡å‹è§£é‡Š
        3. ç‰¹å¾èåˆç ”ç©¶

        Args:
            x: è¾“å…¥å¼ é‡

        Returns:
            åŒ…å«ä¸åŒå±‚çº§ç‰¹å¾çš„å­—å…¸
        """
        features = {}

        # ä¸Šé‡‡æ ·
        if x.shape[-1] != 224:
            x = F.interpolate(x, size=(224, 224), mode="bilinear", align_corners=False)

        # è·å–patch embedding
        if hasattr(self.backbone, "patch_embed"):
            x = self.backbone.patch_embed(x)
            features["patch_embed"] = x

        # é€šè¿‡å„ä¸ªstageï¼ˆå¦‚æœå¯ä»¥è®¿é—®ï¼‰
        if hasattr(self.backbone, "layers"):
            for i, layer in enumerate(self.backbone.layers):
                x = layer(x)
                features[f"stage_{i}"] = x

        # æœ€ç»ˆç‰¹å¾
        if hasattr(self.backbone, "norm") and hasattr(self.backbone, "avgpool"):
            x = self.backbone.norm(x)
            x = self.backbone.avgpool(x)
            x = torch.flatten(x, 1)
            features["final"] = x
        else:
            # å¦‚æœç»“æ„ä¸åŒï¼Œä½¿ç”¨å®Œæ•´çš„å‰å‘ä¼ æ’­
            features["final"] = self.backbone(x)

        return features

    @classmethod
    def from_config(cls, cfg: DictConfig) -> "OpticalSwinModel":
        """
        ä»é…ç½®åˆ›å»ºæ¨¡å‹å®ä¾‹

        è¿™æ˜¯å·¥å‚æ–¹æ³•æ¨¡å¼çš„å®ç°ã€‚é€šè¿‡é…ç½®æ–‡ä»¶å°±èƒ½åˆ›å»ºæ¨¡å‹ï¼Œ
        è€Œä¸éœ€è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç æ¨¡å‹å‚æ•°ã€‚

        Args:
            cfg: å®Œæ•´çš„é…ç½®å¯¹è±¡

        Returns:
            é…ç½®å¥½çš„OpticalSwinModelå®ä¾‹
        """
        model_cfg = cfg.model

        return cls(
            model_name=model_cfg.get("backbone_name", "swin_tiny_patch4_window7_224"),
            input_channels=model_cfg.get("input_channels", 5),
            pretrained=model_cfg.get("pretrained", True),
            dropout_rate=model_cfg.get("dropout_rate", 0.2),
        )

    def freeze_patch_embed(self) -> None:
        """
        åªå†»ç»“patch embeddingå±‚

        è¿™æ˜¯ä¸€ä¸ªæ›´ç²¾ç»†çš„å†»ç»“ç­–ç•¥ï¼Œåœ¨æŸäº›åœºæ™¯ä¸‹å¾ˆæœ‰ç”¨ï¼š
        å½“æˆ‘ä»¬æƒ³ä¿æŒè¾“å…¥å±‚çš„æƒé‡ä¸å˜ï¼ˆç‰¹åˆ«æ˜¯æˆ‘ä»¬ç²¾å¿ƒåˆå§‹åŒ–çš„æƒé‡ï¼‰ï¼Œ
        ä½†å…è®¸æ›´æ·±å±‚çš„ç‰¹å¾å­¦ä¹ ã€‚
        """
        if hasattr(self.backbone, "patch_embed"):
            for param in self.backbone.patch_embed.parameters():
                param.requires_grad = False
            logger.info("Frozen patch embedding layer")
        else:
            logger.warning("patch_embed not found, cannot freeze")

    def unfreeze_patch_embed(self) -> None:
        """è§£å†»patch embeddingå±‚"""
        if hasattr(self.backbone, "patch_embed"):
            for param in self.backbone.patch_embed.parameters():
                param.requires_grad = True
            logger.info("Unfrozen patch embedding layer")

    def get_layer_wise_lr_groups(self, base_lr: float = 1e-4, decay_factor: float = 0.8):
        """
        ä¸ºSwin Transformeråˆ›å»ºå±‚æ¬¡åŒ–å­¦ä¹ ç‡

        Swin Transformeræœ‰æ˜ç¡®çš„å±‚æ¬¡ç»“æ„ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºä¸åŒçš„stage
        è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡ã€‚é€šå¸¸è§„å¾‹æ˜¯ï¼š
        - patch_embedï¼šæœ€å°å­¦ä¹ ç‡ï¼ˆæœ€åŸºç¡€çš„ç‰¹å¾ï¼‰
        - æ—©æœŸstageï¼šè¾ƒå°å­¦ä¹ ç‡
        - åæœŸstageï¼šè¾ƒå¤§å­¦ä¹ ç‡
        - åˆ†ç±»å¤´ï¼šæœ€å¤§å­¦ä¹ ç‡

        Args:
            base_lr: åŸºç¡€å­¦ä¹ ç‡
            decay_factor: æ¯å‘å‰ä¸€stageï¼Œå­¦ä¹ ç‡çš„è¡°å‡å› å­

        Returns:
            å‚æ•°ç»„åˆ—è¡¨ï¼Œæ¯ç»„æœ‰ä¸åŒçš„å­¦ä¹ ç‡
        """
        param_groups = []

        # Patch embedding - æœ€å°å­¦ä¹ ç‡
        if hasattr(self.backbone, "patch_embed"):
            param_groups.append(
                {
                    "params": list(self.backbone.patch_embed.parameters()),
                    "lr": base_lr * (decay_factor**4),
                    "name": "patch_embed",
                }
            )

        # Swin stages - é€’å¢å­¦ä¹ ç‡
        if hasattr(self.backbone, "layers"):
            for i, layer in enumerate(self.backbone.layers):
                param_groups.append(
                    {
                        "params": list(layer.parameters()),
                        "lr": base_lr * (decay_factor ** (3 - i)),
                        "name": f"stage_{i}",
                    }
                )

        # Normå±‚å’Œå…¶ä»–å‰©ä½™å‚æ•°
        remaining_params = []
        processed_params = set()

        # æ”¶é›†å·²å¤„ç†çš„å‚æ•°
        for group in param_groups:
            for param in group["params"]:
                processed_params.add(id(param))  # id() è¿”å›å¯¹è±¡çš„å”¯ä¸€æ ‡è¯†ç¬¦

        # æ”¶é›†æœªå¤„ç†çš„å‚æ•°
        for param in self.backbone.parameters():
            if id(param) not in processed_params:
                remaining_params.append(param)

        if remaining_params:  # å¦‚æœå­˜åœ¨æœªå¤„ç†çš„å‚æ•°ï¼Œåˆ™æ·»åŠ åˆ°å‚æ•°ç»„ä¸­
            param_groups.append({"params": remaining_params, "lr": base_lr, "name": "others"})

        logger.info(f"Created {len(param_groups)} parameter groups with layer-wise learning rates")
        return param_groups


# ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºä¸åŒå˜ä½“çš„æ¨¡å‹
def create_swin_tiny(input_channels: int = 5, pretrained: bool = True, dropout_rate: float = 0.2) -> OpticalSwinModel:
    """åˆ›å»ºSwin Tinyæ¨¡å‹"""
    return OpticalSwinModel(
        model_name="swin_tiny_patch4_window7_224",
        input_channels=input_channels,
        pretrained=pretrained,
        dropout_rate=dropout_rate,
    )


def create_swin_small(input_channels: int = 5, pretrained: bool = True, dropout_rate: float = 0.2) -> OpticalSwinModel:
    """åˆ›å»ºSwin Smallæ¨¡å‹"""
    return OpticalSwinModel(
        model_name="swin_small_patch4_window7_224",
        input_channels=input_channels,
        pretrained=pretrained,
        dropout_rate=dropout_rate,
    )


def create_swin_base(input_channels: int = 5, pretrained: bool = True, dropout_rate: float = 0.2) -> OpticalSwinModel:
    """åˆ›å»ºSwin Baseæ¨¡å‹"""
    return OpticalSwinModel(
        model_name="swin_base_patch4_window7_224",
        input_channels=input_channels,
        pretrained=pretrained,
        dropout_rate=dropout_rate,
    )


# æµ‹è¯•å‡½æ•°
def test_optical_swin_model():
    """æµ‹è¯•æ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½"""
    import torch

    print("Testing OpticalSwinModel...")

    # åˆ›å»ºæ¨¡å‹
    model = create_swin_tiny()
    model.eval()

    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 2
    test_input = torch.randn(batch_size, 5, 64, 64)

    # å‰å‘ä¼ æ’­æµ‹è¯•
    with torch.no_grad():
        features = model(test_input)
        print(f"Input shape: {test_input.shape}")
        print(f"Output features shape: {features.shape}")
        print(f"Feature dimension: {model.get_feature_dim()}")

    # æ¨¡å‹ä¿¡æ¯æµ‹è¯•
    model.summary()

    print("âœ“ OpticalSwinModel test passed!")


if __name__ == "__main__":
    test_optical_swin_model()
