# =============================================================================
# lightning_landslide/src/active_learning/__init__.py
# =============================================================================

"""
MM-LandslideNet ä¸»åŠ¨å­¦ä¹ æ¨¡å—

è¿™ä¸ªæ¨¡å—æä¾›äº†å®Œæ•´çš„ä¸»åŠ¨å­¦ä¹ +ä¼ªæ ‡ç­¾èåˆåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- ä¸ç¡®å®šæ€§ä¼°è®¡
- ä¼ªæ ‡ç­¾ç”Ÿæˆ
- ä¸»åŠ¨å­¦ä¹ æ ·æœ¬é€‰æ‹©
- æ•°æ®ç®¡ç†å’Œç‰ˆæœ¬æ§åˆ¶
- å¯è§†åŒ–åˆ†æ
- å®Œæ•´çš„è®­ç»ƒæµç¨‹

ä¸»è¦ç»„ä»¶ï¼š
- UncertaintyEstimator: å¤šç§ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•
- PseudoLabelGenerator: æ™ºèƒ½ä¼ªæ ‡ç­¾ç”Ÿæˆ
- ActiveLearningSelector: ä¸»åŠ¨å­¦ä¹ æ ·æœ¬é€‰æ‹©
- ActivePseudoTrainer: èåˆè®­ç»ƒå™¨
- ActiveKFoldTrainer: KæŠ˜+ä¸»åŠ¨å­¦ä¹ è®­ç»ƒå™¨
- EnhancedDataManager: æ•°æ®ç®¡ç†å™¨
- ActiveLearningVisualizer: å¯è§†åŒ–å·¥å…·
"""

__version__ = "1.0.0"
__author__ = "MM-LandslideNet Team"

import logging
from typing import Dict, Any, Optional
import warnings

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# æ ¸å¿ƒç»„ä»¶å¯¼å…¥
try:
    from .uncertainty_estimator import (
        BaseUncertaintyEstimator,
        MCDropoutEstimator,
        DeepEnsembleEstimator,
        HybridUncertaintyEstimator,
        TemperatureScaling,
        UncertaintyResults,
        create_uncertainty_estimator,
    )

    logger.debug("âœ“ Uncertainty estimation components loaded")
except ImportError as e:
    logger.error(f"Failed to import uncertainty estimation components: {e}")
    raise

try:
    from .pseudo_label_generator import (
        PseudoLabelGenerator,
        PseudoLabelSample,
        PseudoLabelResults,
        AdaptiveThresholdScheduler,
        ClassBalanceController,
        create_pseudo_label_generator,
    )

    logger.debug("âœ“ Pseudo labeling components loaded")
except ImportError as e:
    logger.error(f"Failed to import pseudo labeling components: {e}")
    raise

try:
    from .active_learning_selector import (
        BaseActiveLearningStrategy,
        UncertaintyStrategy,
        DiversityStrategy,
        ClusterBasedStrategy,
        QueryByCommitteeStrategy,
        HybridActiveLearningSelector,
        ActiveLearningQuery,
        ActiveLearningResults,
        create_active_learning_selector,
    )

    logger.debug("âœ“ Active learning selection components loaded")
except ImportError as e:
    logger.error(f"Failed to import active learning selection components: {e}")
    raise

try:
    from .active_pseudo_trainer import (
        ActivePseudoTrainer,
        ActivePseudoTrainingResults,
        IterationResults,
        create_active_pseudo_trainer,
    )

    logger.debug("âœ“ Active pseudo training components loaded")
except ImportError as e:
    logger.error(f"Failed to import active pseudo training components: {e}")
    raise

try:
    from .data_management import (
        EnhancedDataManager,
        DataSample,
        DatasetVersion,
        CombinedDataset,
        BaseAnnotationInterface,
        SimulatedAnnotationInterface,
        WebAnnotationInterface,
        create_annotation_interface,
        create_enhanced_data_manager,
    )

    logger.debug("âœ“ Data management components loaded")
except ImportError as e:
    logger.error(f"Failed to import data management components: {e}")
    raise

try:
    from .visualization import ActiveLearningVisualizer, VisualizationConfig, create_visualizer

    logger.debug("âœ“ Visualization components loaded")
except ImportError as e:
    logger.error(f"Failed to import visualization components: {e}")
    raise

# å¯é€‰ç»„ä»¶å¯¼å…¥ï¼ˆKæŠ˜è®­ç»ƒå™¨ï¼‰
try:
    from ..training.active_kfold_trainer import ActiveKFoldTrainer, ActiveKFoldResults, create_active_kfold_trainer

    logger.debug("âœ“ Active K-fold training components loaded")
except ImportError as e:
    logger.warning(f"Active K-fold trainer not available: {e}")
    ActiveKFoldTrainer = None
    ActiveKFoldResults = None
    create_active_kfold_trainer = None


# å…¬å…±æ¥å£
__all__ = [
    # æ ¸å¿ƒç»„ä»¶
    "ActivePseudoTrainer",
    "create_active_pseudo_trainer",
    # ä¸ç¡®å®šæ€§ä¼°è®¡
    "BaseUncertaintyEstimator",
    "MCDropoutEstimator",
    "DeepEnsembleEstimator",
    "HybridUncertaintyEstimator",
    "TemperatureScaling",
    "UncertaintyResults",
    "create_uncertainty_estimator",
    # ä¼ªæ ‡ç­¾ç”Ÿæˆ
    "PseudoLabelGenerator",
    "PseudoLabelSample",
    "PseudoLabelResults",
    "AdaptiveThresholdScheduler",
    "ClassBalanceController",
    "create_pseudo_label_generator",
    # ä¸»åŠ¨å­¦ä¹ é€‰æ‹©
    "BaseActiveLearningStrategy",
    "UncertaintyStrategy",
    "DiversityStrategy",
    "ClusterBasedStrategy",
    "QueryByCommitteeStrategy",
    "HybridActiveLearningSelector",
    "ActiveLearningQuery",
    "ActiveLearningResults",
    "create_active_learning_selector",
    # æ•°æ®ç®¡ç†
    "EnhancedDataManager",
    "DataSample",
    "DatasetVersion",
    "CombinedDataset",
    "BaseAnnotationInterface",
    "SimulatedAnnotationInterface",
    "WebAnnotationInterface",
    "create_annotation_interface",
    "create_enhanced_data_manager",
    # å¯è§†åŒ–
    "ActiveLearningVisualizer",
    "VisualizationConfig",
    "create_visualizer",
    # ç»“æœç±»å‹
    "ActivePseudoTrainingResults",
    "IterationResults",
]

# æ·»åŠ KæŠ˜ç›¸å…³ç»„ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
if ActiveKFoldTrainer is not None:
    __all__.extend(["ActiveKFoldTrainer", "ActiveKFoldResults", "create_active_kfold_trainer"])


class ActiveLearningError(Exception):
    """ä¸»åŠ¨å­¦ä¹ æ¨¡å—çš„åŸºç¡€å¼‚å¸¸ç±»"""

    pass


def create_active_learning_pipeline(
    config: Dict[str, Any], experiment_name: str = None, output_dir: str = None, enable_kfold: bool = False
) -> Any:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºå®Œæ•´çš„ä¸»åŠ¨å­¦ä¹ æµæ°´çº¿

    Args:
        config: å®Œæ•´é…ç½®å­—å…¸
        experiment_name: å®éªŒåç§°
        output_dir: è¾“å‡ºç›®å½•
        enable_kfold: æ˜¯å¦å¯ç”¨KæŠ˜äº¤å‰éªŒè¯

    Returns:
        è®­ç»ƒå™¨å®ä¾‹

    Raises:
        ActiveLearningError: é…ç½®é”™è¯¯æˆ–ç»„ä»¶åˆ›å»ºå¤±è´¥
    """
    try:
        if enable_kfold and ActiveKFoldTrainer is not None:
            logger.info("ğŸ”„ Creating Active K-fold training pipeline")
            return create_active_kfold_trainer(config=config, experiment_name=experiment_name, output_dir=output_dir)
        else:
            logger.info("ğŸ¯ Creating Active pseudo-label training pipeline")
            return create_active_pseudo_trainer(config=config, experiment_name=experiment_name, output_dir=output_dir)

    except Exception as e:
        raise ActiveLearningError(f"Failed to create active learning pipeline: {e}") from e


def validate_active_learning_config(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    éªŒè¯ä¸»åŠ¨å­¦ä¹ é…ç½®çš„æœ‰æ•ˆæ€§

    Args:
        config: é…ç½®å­—å…¸

    Returns:
        éªŒè¯å’Œä¿®æ­£åçš„é…ç½®

    Raises:
        ActiveLearningError: é…ç½®éªŒè¯å¤±è´¥
    """
    logger.info("ğŸ” Validating active learning configuration...")

    # æ·±æ‹·è´é…ç½®ä»¥é¿å…ä¿®æ”¹åŸå§‹é…ç½®
    import copy

    validated_config = copy.deepcopy(config)

    # æ£€æŸ¥å¿…éœ€çš„é¡¶çº§é…ç½®èŠ‚
    required_sections = ["model", "data", "trainer"]
    for section in required_sections:
        if section not in validated_config:
            raise ActiveLearningError(f"Missing required configuration section: {section}")

    # æ£€æŸ¥ä¸»åŠ¨å­¦ä¹ é…ç½®
    if "active_pseudo_learning" not in validated_config:
        logger.warning("No active_pseudo_learning section found, using defaults")
        validated_config["active_pseudo_learning"] = {}

    apl_config = validated_config["active_pseudo_learning"]

    # éªŒè¯å’Œè®¾ç½®é»˜è®¤å€¼
    default_apl_config = {
        "max_iterations": 5,
        "convergence_threshold": 0.01,
        "min_improvement_iterations": 2,
        "annotation_budget": 50,
        "uncertainty_estimation": {
            "method": "mc_dropout",
            "params": {"n_forward_passes": 30, "use_temperature_scaling": True},
        },
        "pseudo_labeling": {
            "confidence_threshold": 0.9,
            "uncertainty_threshold": 0.1,
            "use_adaptive_threshold": True,
            "use_class_balance": True,
        },
        "active_learning": {
            "budget_per_iteration": 50,
            "strategies": {"uncertainty": 0.5, "diversity": 0.3, "cluster_based": 0.2},
        },
    }

    # é€’å½’åˆå¹¶é»˜è®¤é…ç½®
    def merge_configs(default: Dict, user: Dict) -> Dict:
        for key, value in default.items():
            if key not in user:
                user[key] = value
            elif isinstance(value, dict) and isinstance(user[key], dict):
                merge_configs(value, user[key])
        return user

    apl_config = merge_configs(default_apl_config, apl_config)
    validated_config["active_pseudo_learning"] = apl_config

    # éªŒè¯å‚æ•°èŒƒå›´
    validations = [
        ("max_iterations", 1, 20, "Maximum iterations must be between 1 and 20"),
        ("convergence_threshold", 0.001, 0.1, "Convergence threshold must be between 0.001 and 0.1"),
        ("annotation_budget", 1, 1000, "Annotation budget must be between 1 and 1000"),
    ]

    for param, min_val, max_val, error_msg in validations:
        if param in apl_config:
            value = apl_config[param]
            if not (min_val <= value <= max_val):
                raise ActiveLearningError(f"{error_msg}, got {value}")

    # éªŒè¯ä¼ªæ ‡ç­¾é…ç½®
    pseudo_config = apl_config["pseudo_labeling"]
    confidence_threshold = pseudo_config["confidence_threshold"]
    uncertainty_threshold = pseudo_config["uncertainty_threshold"]

    if not (0.5 <= confidence_threshold <= 0.99):
        raise ActiveLearningError(f"Confidence threshold must be between 0.5 and 0.99, got {confidence_threshold}")

    if not (0.01 <= uncertainty_threshold <= 0.5):
        raise ActiveLearningError(f"Uncertainty threshold must be between 0.01 and 0.5, got {uncertainty_threshold}")

    # éªŒè¯ç­–ç•¥æƒé‡
    strategies = apl_config["active_learning"]["strategies"]
    total_weight = sum(strategies.values())
    if abs(total_weight - 1.0) > 0.01:
        logger.warning(f"Strategy weights sum to {total_weight:.3f}, normalizing to 1.0")
        for strategy in strategies:
            strategies[strategy] /= total_weight

    logger.info("âœ… Configuration validation completed")
    return validated_config


def get_active_learning_info() -> Dict[str, Any]:
    """
    è·å–ä¸»åŠ¨å­¦ä¹ æ¨¡å—ä¿¡æ¯

    Returns:
        æ¨¡å—ä¿¡æ¯å­—å…¸
    """
    return {
        "version": __version__,
        "author": __author__,
        "components": {
            "uncertainty_estimation": ["mc_dropout", "deep_ensemble", "hybrid"],
            "pseudo_labeling": ["adaptive_threshold", "class_balance", "quality_control"],
            "active_learning": ["uncertainty", "diversity", "cluster_based", "query_by_committee"],
            "data_management": ["version_control", "annotation_interface", "combined_dataset"],
            "visualization": ["static_plots", "interactive_dashboard", "comparison_reports"],
            "training": ["active_pseudo", "active_kfold"],
        },
        "supported_tasks": ["active_train", "active_kfold"],
        "requirements": {
            "pytorch": ">=1.9.0",
            "pytorch_lightning": ">=1.5.0",
            "numpy": ">=1.20.0",
            "pandas": ">=1.3.0",
            "scikit-learn": ">=0.24.0",
            "matplotlib": ">=3.3.0",
            "seaborn": ">=0.11.0",
            "plotly": ">=5.0.0",
        },
    }


# æ¨¡å—çº§åˆ«çš„ä¾¿æ·å‡½æ•°
def quick_start_active_learning(
    train_data_dir: str,
    test_data_dir: str,
    train_csv: str,
    test_csv: str,
    model_name: str = "swin_tiny_patch4_window7_224",
    experiment_name: str = None,
    max_iterations: int = 5,
) -> Dict[str, Any]:
    """
    å¿«é€Ÿå¯åŠ¨ä¸»åŠ¨å­¦ä¹ çš„ä¾¿æ·å‡½æ•°

    Args:
        train_data_dir: è®­ç»ƒæ•°æ®ç›®å½•
        test_data_dir: æµ‹è¯•æ•°æ®ç›®å½•
        train_csv: è®­ç»ƒæ ‡ç­¾æ–‡ä»¶
        test_csv: æµ‹è¯•æ ‡ç­¾æ–‡ä»¶
        model_name: æ¨¡å‹åç§°
        experiment_name: å®éªŒåç§°
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°

    Returns:
        è®­ç»ƒç»“æœå­—å…¸
    """
    logger.info("ğŸš€ Quick start active learning...")

    # åˆ›å»ºé»˜è®¤é…ç½®
    config = {
        "experiment_name": experiment_name or f"quick_active_{int(__import__('time').time())}",
        "seed": 3407,
        "log_level": "INFO",
        "model": {
            "target": "lightning_landslide.src.models.LandslideClassificationModule",
            "params": {
                "base_model": {
                    "target": "lightning_landslide.src.models.optical_swin.OpticalSwinModel",
                    "params": {"model_name": model_name, "input_channels": 5, "num_classes": 1},
                }
            },
        },
        "data": {
            "target": "lightning_landslide.src.data.MultiModalDataModule",
            "params": {
                "train_data_dir": train_data_dir,
                "test_data_dir": test_data_dir,
                "train_csv": train_csv,
                "test_csv": test_csv,
                "batch_size": 32,
                "num_workers": 4,
            },
        },
        "trainer": {
            "target": "pytorch_lightning.Trainer",
            "params": {"max_epochs": 30, "accelerator": "auto", "devices": "auto"},
        },
        "active_pseudo_learning": {"max_iterations": max_iterations, "annotation_budget": 50},
        "outputs": {"base_output_dir": "outputs"},
    }

    # éªŒè¯é…ç½®
    config = validate_active_learning_config(config)

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = create_active_learning_pipeline(config)

    # è¿è¡Œè®­ç»ƒ
    results = trainer.run()

    logger.info("âœ… Quick start active learning completed")
    return results.to_dict() if hasattr(results, "to_dict") else results


# é”™è¯¯å¤„ç†è£…é¥°å™¨
def handle_active_learning_errors(func):
    """è£…é¥°å™¨ï¼šç»Ÿä¸€å¤„ç†ä¸»åŠ¨å­¦ä¹ ç›¸å…³é”™è¯¯"""

    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except ActiveLearningError:
            # é‡æ–°æŠ›å‡ºä¸»åŠ¨å­¦ä¹ ç›¸å…³é”™è¯¯
            raise
        except Exception as e:
            # åŒ…è£…å…¶ä»–å¼‚å¸¸
            logger.error(f"Unexpected error in {func.__name__}: {e}")
            raise ActiveLearningError(f"Unexpected error in {func.__name__}: {e}") from e

    return wrapper


# æ¨¡å—åˆå§‹åŒ–æ—¶çš„æ£€æŸ¥
def _check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    try:
        import torch
        import pytorch_lightning as pl
        import numpy as np
        import pandas as pd
        import sklearn
        import matplotlib
        import seaborn as sns

        logger.debug("âœ“ All required dependencies available")
    except ImportError as e:
        logger.error(f"Missing required dependency: {e}")
        raise ImportError(f"Missing required dependency for active learning module: {e}")


def _suppress_warnings():
    """æŠ‘åˆ¶ä¸å¿…è¦çš„è­¦å‘Š"""
    warnings.filterwarnings("ignore", category=UserWarning, module="pytorch_lightning")
    warnings.filterwarnings("ignore", category=FutureWarning, module="sklearn")
    warnings.filterwarnings("ignore", category=RuntimeWarning, module="matplotlib")


# æ¨¡å—åˆå§‹åŒ–
try:
    _check_dependencies()
    _suppress_warnings()
    logger.info(f"ğŸ¯ MM-LandslideNet Active Learning Module v{__version__} loaded successfully")
except Exception as e:
    logger.error(f"Failed to initialize active learning module: {e}")
    raise
