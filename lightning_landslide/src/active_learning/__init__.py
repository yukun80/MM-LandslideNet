# =============================================================================
# lightning_landslide/src/active_learning/__init__.py
# =============================================================================

"""
MM-LandslideNet ä¸»åŠ¨å­¦ä¹ æ¨¡å—

è¿™ä¸ªæ¨¡å—æä¾›äº†å®Œæ•´çš„ä¸»åŠ¨å­¦ä¹ +ä¼ªæ ‡ç­¾èåˆåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- ä¸ç¡®å®šæ€§ä¼°è®¡
- ä¼ªæ ‡ç­¾ç”Ÿæˆ
- ä¸»åŠ¨å­¦ä¹ æ ·æœ¬é€‰æ‹©
- æ•°æ®ç®¡ç†å’Œç‰ˆæœ¬æ§åˆ¶
- å¯è§†åŒ–åˆ†æ
- å®Œæ•´çš„è®­ç»ƒæµç¨‹

ä¸»è¦ç»„ä»¶ï¼š
- UncertaintyEstimator: å¤šç§ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•
- PseudoLabelGenerator: æ™ºèƒ½ä¼ªæ ‡ç­¾ç”Ÿæˆ
- ActiveLearningSelector: ä¸»åŠ¨å­¦ä¹ æ ·æœ¬é€‰æ‹©
- ActivePseudoTrainer: èåˆè®­ç»ƒå™¨
- ActiveKFoldTrainer: KæŠ˜+ä¸»åŠ¨å­¦ä¹ è®­ç»ƒå™¨
- EnhancedDataManager: æ•°æ®ç®¡ç†å™¨
- ActiveLearningVisualizer: å¯è§†åŒ–å·¥å…·
"""

__version__ = "1.0.0"
__author__ = "MM-LandslideNet Team"

import logging
from typing import Dict, Any, Optional
import warnings

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# æ ¸å¿ƒç»„ä»¶å¯¼å…¥
try:
    from .uncertainty_estimator import (
        BaseUncertaintyEstimator,
        MCDropoutEstimator,
        DeepEnsembleEstimator,
        HybridUncertaintyEstimator,
        TemperatureScaling,
        UncertaintyResults,
        create_uncertainty_estimator,
    )

    logger.debug("âœ“ Uncertainty estimation components loaded")
except ImportError as e:
    logger.error(f"Failed to import uncertainty estimation components: {e}")
    raise


try:
    from .visualization import ActiveLearningVisualizer, VisualizationConfig, create_visualizer

    logger.debug("âœ“ Visualization components loaded")
except ImportError as e:
    logger.error(f"Failed to import visualization components: {e}")
    raise

# å¯é€‰ç»„ä»¶å¯¼å…¥ï¼ˆKæŠ˜è®­ç»ƒå™¨ï¼‰
try:
    from ..training.active_kfold_trainer import ActiveKFoldTrainer, ActiveKFoldResults, create_active_kfold_trainer

    logger.debug("âœ“ Active K-fold training components loaded")
except ImportError as e:
    logger.warning(f"Active K-fold trainer not available: {e}")
    ActiveKFoldTrainer = None
    ActiveKFoldResults = None
    create_active_kfold_trainer = None


# å…¬å…±æ¥å£
__all__ = [
    # æ ¸å¿ƒç»„ä»¶
    "ActivePseudoTrainer",
    "create_active_pseudo_trainer",
    # ä¸ç¡®å®šæ€§ä¼°è®¡
    "BaseUncertaintyEstimator",
    "MCDropoutEstimator",
    "DeepEnsembleEstimator",
    "HybridUncertaintyEstimator",
    "TemperatureScaling",
    "UncertaintyResults",
    "create_uncertainty_estimator",
    # ä¼ªæ ‡ç­¾ç”Ÿæˆ
    "PseudoLabelGenerator",
    "PseudoLabelSample",
    "PseudoLabelResults",
    "AdaptiveThresholdScheduler",
    "ClassBalanceController",
    "create_pseudo_label_generator",
    # ä¸»åŠ¨å­¦ä¹ é€‰æ‹©
    "BaseActiveLearningStrategy",
    "UncertaintyStrategy",
    "DiversityStrategy",
    "ClusterBasedStrategy",
    "QueryByCommitteeStrategy",
    "HybridActiveLearningSelector",
    "ActiveLearningQuery",
    "ActiveLearningResults",
    "create_active_learning_selector",
    # æ•°æ®ç®¡ç†
    "EnhancedDataManager",
    "DataSample",
    "DatasetVersion",
    "CombinedDataset",
    "BaseAnnotationInterface",
    "SimulatedAnnotationInterface",
    "WebAnnotationInterface",
    "create_annotation_interface",
    "create_enhanced_data_manager",
    # å¯è§†åŒ–
    "ActiveLearningVisualizer",
    "VisualizationConfig",
    "create_visualizer",
    # ç»“æœç±»å‹
    "ActivePseudoTrainingResults",
    "IterationResults",
]

# æ·»åŠ KæŠ˜ç›¸å…³ç»„ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
if ActiveKFoldTrainer is not None:
    __all__.extend(["ActiveKFoldTrainer", "ActiveKFoldResults", "create_active_kfold_trainer"])


class ActiveLearningError(Exception):
    """ä¸»åŠ¨å­¦ä¹ æ¨¡å—çš„åŸºç¡€å¼‚å¸¸ç±»"""

    pass


def validate_active_learning_config(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    éªŒè¯ä¸»åŠ¨å­¦ä¹ é…ç½®çš„æœ‰æ•ˆæ€§

    Args:
        config: é…ç½®å­—å…¸

    Returns:
        éªŒè¯å’Œä¿®æ­£åçš„é…ç½®

    Raises:
        ActiveLearningError: é…ç½®éªŒè¯å¤±è´¥
    """
    logger.info("ğŸ” Validating active learning configuration...")

    # æ·±æ‹·è´é…ç½®ä»¥é¿å…ä¿®æ”¹åŸå§‹é…ç½®
    import copy

    validated_config = copy.deepcopy(config)

    # æ£€æŸ¥å¿…éœ€çš„é¡¶çº§é…ç½®èŠ‚
    required_sections = ["model", "data", "trainer"]
    for section in required_sections:
        if section not in validated_config:
            raise ActiveLearningError(f"Missing required configuration section: {section}")

    # æ£€æŸ¥ä¸»åŠ¨å­¦ä¹ é…ç½®
    if "active_pseudo_learning" not in validated_config:
        logger.warning("No active_pseudo_learning section found, using defaults")
        validated_config["active_pseudo_learning"] = {}

    apl_config = validated_config["active_pseudo_learning"]

    # éªŒè¯å’Œè®¾ç½®é»˜è®¤å€¼
    default_apl_config = {
        "max_iterations": 5,
        "convergence_threshold": 0.01,
        "min_improvement_iterations": 2,
        "annotation_budget": 50,
        "uncertainty_estimation": {
            "method": "mc_dropout",
            "params": {"n_forward_passes": 30, "use_temperature_scaling": True},
        },
        "pseudo_labeling": {
            "confidence_threshold": 0.9,
            "uncertainty_threshold": 0.1,
            "use_adaptive_threshold": True,
            "use_class_balance": True,
        },
        "active_learning": {
            "budget_per_iteration": 50,
            "strategies": {"uncertainty": 0.5, "diversity": 0.3, "cluster_based": 0.2},
        },
    }

    # é€’å½’åˆå¹¶é»˜è®¤é…ç½®
    def merge_configs(default: Dict, user: Dict) -> Dict:
        for key, value in default.items():
            if key not in user:
                user[key] = value
            elif isinstance(value, dict) and isinstance(user[key], dict):
                merge_configs(value, user[key])
        return user

    apl_config = merge_configs(default_apl_config, apl_config)
    validated_config["active_pseudo_learning"] = apl_config

    # éªŒè¯å‚æ•°èŒƒå›´
    validations = [
        ("max_iterations", 1, 20, "Maximum iterations must be between 1 and 20"),
        ("convergence_threshold", 0.001, 0.1, "Convergence threshold must be between 0.001 and 0.1"),
        ("annotation_budget", 1, 1000, "Annotation budget must be between 1 and 1000"),
    ]

    for param, min_val, max_val, error_msg in validations:
        if param in apl_config:
            value = apl_config[param]
            if not (min_val <= value <= max_val):
                raise ActiveLearningError(f"{error_msg}, got {value}")

    # éªŒè¯ä¼ªæ ‡ç­¾é…ç½®
    pseudo_config = apl_config["pseudo_labeling"]
    confidence_threshold = pseudo_config["confidence_threshold"]
    uncertainty_threshold = pseudo_config["uncertainty_threshold"]

    if not (0.5 <= confidence_threshold <= 0.99):
        raise ActiveLearningError(f"Confidence threshold must be between 0.5 and 0.99, got {confidence_threshold}")

    if not (0.01 <= uncertainty_threshold <= 0.5):
        raise ActiveLearningError(f"Uncertainty threshold must be between 0.01 and 0.5, got {uncertainty_threshold}")

    # éªŒè¯ç­–ç•¥æƒé‡
    strategies = apl_config["active_learning"]["strategies"]
    total_weight = sum(strategies.values())
    if abs(total_weight - 1.0) > 0.01:
        logger.warning(f"Strategy weights sum to {total_weight:.3f}, normalizing to 1.0")
        for strategy in strategies:
            strategies[strategy] /= total_weight

    logger.info("âœ… Configuration validation completed")
    return validated_config


def get_active_learning_info() -> Dict[str, Any]:
    """
    è·å–ä¸»åŠ¨å­¦ä¹ æ¨¡å—ä¿¡æ¯

    Returns:
        æ¨¡å—ä¿¡æ¯å­—å…¸
    """
    return {
        "version": __version__,
        "author": __author__,
        "components": {
            "uncertainty_estimation": ["mc_dropout", "deep_ensemble", "hybrid"],
            "pseudo_labeling": ["adaptive_threshold", "class_balance", "quality_control"],
            "active_learning": ["uncertainty", "diversity", "cluster_based", "query_by_committee"],
            "data_management": ["version_control", "annotation_interface", "combined_dataset"],
            "visualization": ["static_plots", "interactive_dashboard", "comparison_reports"],
            "training": ["active_pseudo", "active_kfold"],
        },
        "supported_tasks": ["active_train", "active_kfold"],
        "requirements": {
            "pytorch": ">=1.9.0",
            "pytorch_lightning": ">=1.5.0",
            "numpy": ">=1.20.0",
            "pandas": ">=1.3.0",
            "scikit-learn": ">=0.24.0",
            "matplotlib": ">=3.3.0",
            "seaborn": ">=0.11.0",
            "plotly": ">=5.0.0",
        },
    }


# æ¨¡å—çº§åˆ«çš„ä¾¿æ·å‡½æ•°


# é”™è¯¯å¤„ç†è£…é¥°å™¨
def handle_active_learning_errors(func):
    """è£…é¥°å™¨ï¼šç»Ÿä¸€å¤„ç†ä¸»åŠ¨å­¦ä¹ ç›¸å…³é”™è¯¯"""

    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except ActiveLearningError:
            # é‡æ–°æŠ›å‡ºä¸»åŠ¨å­¦ä¹ ç›¸å…³é”™è¯¯
            raise
        except Exception as e:
            # åŒ…è£…å…¶ä»–å¼‚å¸¸
            logger.error(f"Unexpected error in {func.__name__}: {e}")
            raise ActiveLearningError(f"Unexpected error in {func.__name__}: {e}") from e

    return wrapper


def _suppress_warnings():
    """æŠ‘åˆ¶ä¸å¿…è¦çš„è­¦å‘Š"""
    warnings.filterwarnings("ignore", category=UserWarning, module="pytorch_lightning")
    warnings.filterwarnings("ignore", category=FutureWarning, module="sklearn")
    warnings.filterwarnings("ignore", category=RuntimeWarning, module="matplotlib")
