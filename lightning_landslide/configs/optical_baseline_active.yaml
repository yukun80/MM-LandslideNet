# =============================================================================
# configs/optical_baseline_active_complete.yaml - 完整主动学习配置
# =============================================================================

# 实验元信息
experiment_name: "optical_swin_tiny_active_v1"
description: "Active learning with pseudo labeling based on optical baseline"
version: "1.0.0"
tags: ["optical", "active_learning", "pseudo_labeling", "swin"]

author: "MM-LandslideNet Team"
created_date: "2024-07-30"
notes: |
  Active learning experiment based on optical_baseline.yaml configuration.
  Expected to improve F1 score from 0.80 to 0.83+ through intelligent data utilization.

# 全局设置
seed: 3407
log_level: "INFO"

# 模型配置 (保持与基线相同)
model:
  target: lightning_landslide.src.models.LandslideClassificationModule
  params:
    base_model:
      target: lightning_landslide.src.models.optical_swin.OpticalSwinModel
      params:
        model_name: "swinv2_tiny_window16_256"
        input_channels: 5
        pretrained: true
        dropout_rate: 0.2
        pretrained_path: null
        img_size: 256
    
    classifier_config:
      type: "simple"
      hidden_dim: null
      use_batch_norm: false
      activation: "relu"

    loss_config:
      type: "focal"
      focal_params: {alpha: 0.25, gamma: 2.0}
    
    optimizer_config:
      type: "adamw"
      adamw_params: {lr: 4e-5, weight_decay: 1e-2, betas: [0.9, 0.95]}
      differential_lr: {enable: true, backbone_lr_ratio: 0.1, classifier_lr_ratio: 1.0}
    
    scheduler_config:
      type: "cosine_with_warmup"
      cosine_params:
        T_0: 20
        T_mult: 1
        eta_min: 1e-7
    
    metrics_config:
      primary_metric: "f1"
      metrics: ["accuracy", "precision", "recall", "f1", "auroc"]
      threshold: 0.5

# 数据配置 (保持与基线相同)
data:
  target: lightning_landslide.src.data.MultiModalDataModule
  params:
    # 数据路径
    train_data_dir: "dataset/train_data"
    test_data_dir: "dataset/test_data"
    train_csv: "dataset/Train.csv"
    test_csv: "dataset/Test.csv"
    exclude_ids_file: "dataset/data_check/exclude_ids.json"

    # 通道配置
    channel_config:
      channel_groups:
        optical: [0, 1, 2, 3]
        sar_amplitude: [4, 5, 8, 9]
        sar_difference: [6, 7, 10, 11]
        derived: ["ndvi"]
      usage_modes:
        optical_only:
          groups: ["optical", "derived"]
          description: "仅使用光学数据，适合基线实验"
    
    active_mode: "optical_only"
    
    # 数据加载配置
    batch_size: 32
    num_workers: 8
    pin_memory: true
    
    # 数据分割
    val_split: 0.2
    stratify: true
    shuffle_train: true

    # 预处理配置
    preprocessing:
      normalization:
        means: [1849.282, 1953.906, 1896.493, 3291.47, -9.624, -17.110, 
                -0.699, -0.483, -10.671, -18.442, 0.248, -0.234]
        stds: [1414.462, 1338.292, 1342.528, 1448.362, 7.904, 9.245, 
              4.062, 4.283, 6.333, 8.691, 2.777, 3.932]
      ndvi_computation:
        red_channel_idx: 0
        nir_channel_idx: 3
        epsilon: 1e-8
        clip_range: [-1, 1]

    # 数据增强配置
    augmentation:
      train:
        resize: 256
        geometric:
          random_flip: true
          h_flip_prob: 0.5
          v_flip_prob: 0.5
          random_rotation: true
          rotation_prob: 0.3
          rotation_degrees: [-10, 10]
        spectral:
          spectral_noise: true
          noise_std: 0.005
          noise_prob: 0.3
      val: {resize: 256}
      test: {resize: 256}

# 训练器配置 (适配主动学习)
trainer:
  target: pytorch_lightning.Trainer
  params:
    max_epochs: 20  # 主动学习每轮较少epoch
    accelerator: "gpu"
    devices: 1
    precision: "16-mixed"  # "32-true"
    
    log_every_n_steps: 10  # 每10步记录一次
    val_check_interval: 1.0
    check_val_every_n_epoch: 1
    
    gradient_clip_val: 1.0
    accumulate_grad_batches: 1
    
    benchmark: true  # 启用cudnn基准测试
    deterministic: false

# 主动学习+伪标签配置 (核心新增部分)
active_pseudo_learning:
  enabled: true
  max_iterations: 5               # 最大迭代轮数，防止无限迭代，5轮通常足够收敛
  convergence_threshold: 0.001    # 收敛阈值, F1改进<0.001且连续2轮无改进时停止
  min_improvement_iterations: 2   # 最小改进轮数
  annotation_budget: 80           # 每轮最多标注80个样本，控制人工成本
  
  # 不确定性估计配置
  uncertainty_estimation:
    method: "mc_dropout"
    params:
      n_forward_passes: 30
      use_temperature_scaling: true
  
  # 伪标签生成配置
  pseudo_labeling:
    confidence_threshold: 0.85
    uncertainty_threshold: 0.1
    use_adaptive_threshold: true
    use_class_balance: true
    
    # 自适应阈值参数
    adaptive_threshold_params:
      initial_threshold: 0.85
      final_threshold: 0.95
      adjustment_factor: 0.02
    
    quality_weights:
      confidence_weight: 0.4    # 置信度权重最高
      uncertainty_weight: 0.3   # 不确定性权重次之
      consistency_weight: 0.2   # 多次预测一致性
      calibration_weight: 0.1   # 校准后置信度
  
  # 主动学习选择配置
  active_learning:
    budget_per_iteration: 80
    strategies:
      uncertainty: 0.5          # 选择模型最不确定的样本，针对性改进弱点
      diversity: 0.3            # 避免选择相似样本，确保覆盖不同模式
      cluster_based: 0.2        # 从不同数据聚类中选择代表性样本
    
    diversity_params:
      distance_metric: "cosine"
      n_clusters: 10
    
    cluster_params:
      cluster_method: "kmeans"

# 回调函数配置 (简化版)
callbacks:
  model_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      filename: "best-{epoch:02d}-{val_f1:.4f}"
      monitor: "val_f1"
      mode: "max"
      save_top_k: 1
      save_last: true
      verbose: true
  
  early_stopping:
    target: pytorch_lightning.callbacks.EarlyStopping
    params:
      monitor: "val_f1"
      mode: "max"
      patience: 15  # 主动学习中适当减少耐心值
      verbose: true
      strict: false
      min_delta: 0.001
  
  lr_monitor:
    target: pytorch_lightning.callbacks.LearningRateMonitor
    params:
      logging_interval: "epoch"
      log_momentum: false

# 日志记录器配置
loggers:
  tensorboard:
    target: pytorch_lightning.loggers.TensorBoardLogger
    params:
      log_graph: false
      default_hp_metric: true
      name: ""
      version: ""

# 输出目录配置
outputs:
  base_output_dir: "lightning_landslide/exp"
  checkpoint_subdir: "checkpoints"
  log_subdir: "log"
  predictions_subdir: "predictions"

# 计算配置
compute:
  gpu_ids: [0]
  mixed_precision: false
  find_unused_parameters: false
  sync_batchnorm: true
  profiler: null

# 实验特定配置
experiment_config:
  class_balance_strategy: "focal_loss"
  evaluation_strategy:
    use_tta: true
    tta_augmentations: 4
    confidence_threshold: 0.5
  reporting:
    generate_confusion_matrix: true
    generate_roc_curve: true
    generate_precision_recall_curve: true
    save_predictions: true
    save_model_summary: true

# 调试配置
debug:
  fast_dev_run: false
  overfit_batches: 0.0
  validate_data_on_start: true
  run_model_test: false
  profile_model: false

# 实验记录
experiment_log:
  expected_metrics:
    val_f1: 0.83  # 主动学习目标
    val_accuracy: 0.85
    training_time_hours: 3.0  # 主动学习需要更多时间
  baseline_comparison:
    previous_best_f1: 0.80
    improvement_target: 0.03