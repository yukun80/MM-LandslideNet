# =============================================================================
# optical_baseline_active_steps.yaml - åŸºäºæˆåŠŸbaselineçš„åˆ†æ­¥ä¸»åŠ¨å­¦ä¹ é…ç½®
# =============================================================================

# åŸºäº optical_swin_tiny_0724 æˆåŠŸå®éªŒçš„ä¸»åŠ¨å­¦ä¹ é…ç½®
# å‰ç½®æ¡ä»¶ï¼šå·²å®ŒæˆåŸºç¡€è®­ç»ƒå¹¶ä¿å­˜æƒé‡åˆ° lightning_landslide/exp/optical_swin_tiny_0724/checkpoints/

# === å®éªŒå…ƒä¿¡æ¯ ===
experiment_name:  "multimodal_swin_tiny_0803"
description: "Stepwise active learning based on successful optical_swin_tiny_0724 baseline"
version: "2.0.0"

# ç ”ç©¶äººå‘˜ä¿¡æ¯
author: "MM-LandslideNet Team"
notes: |
  åˆ†æ­¥ä¸»åŠ¨å­¦ä¹ å®éªŒï¼ŒåŸºäºæˆåŠŸçš„ optical_swin_tiny_0724 åŸºçº¿æ¨¡å‹ã€‚
  æ”¯æŒä»¥ä¸‹å‘½ä»¤ï¼š
  1. python main.py train config.yaml                    # åŸºç¡€è®­ç»ƒï¼ˆå·²å®Œæˆï¼‰
  2. python main.py uncertainty_estimation config.yaml   # ä¸ç¡®å®šæ€§ä¼°è®¡  
  3. python main.py sample_selection config.yaml         # æ ·æœ¬é€‰æ‹©
  4. python main.py retrain config.yaml                  # æ¨¡å‹fine-tuning

# === å…¨å±€è®¾ç½® ===
seed: 3407
log_level: "INFO"

# === æ¨¡å‹é…ç½® ===
# ä¸ç®€åŒ–åŸºçº¿ä¿æŒå®Œå…¨ä¸€è‡´
model:
  target: lightning_landslide.src.models.LandslideClassificationModule
  params:
    base_model:
      target: lightning_landslide.src.models.optical_swin.OpticalSwinModel
      params:
        model_name: "swinv2_tiny_window16_256"
        input_channels: 13
        pretrained: true
        dropout_rate: 0.2
        pretrained_path: null
        img_size: 256
    
    # åˆ†ç±»å¤´é…ç½® - ä¸baselineä¸€è‡´
    classifier_config:
      type: "simple"              # åˆ†ç±»å¤´ç±»å‹ï¼šsimple/mlp/attention
      hidden_dim: null            # MLPåˆ†ç±»å¤´çš„éšè—ç»´åº¦ï¼ˆsimpleç±»å‹æ—¶å¿½ç•¥ï¼‰
      use_batch_norm: false       # æ˜¯å¦ä½¿ç”¨æ‰¹æ ‡å‡†åŒ–
      activation: "relu"          # åˆ†ç±»å¤´ä¸­çš„æ¿€æ´»å‡½æ•°

    # æŸå¤±å‡½æ•°ï¼šä½¿ç”¨Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡
    loss_config:
      type: "focal"
      focal_params: {alpha: 0.25, gamma: 2.0} # æˆ–è€…0.25ï¼Œéœ€è¦å®éªŒï¼Ÿ
    
    # ä¼˜åŒ–å™¨ï¼šAdamW with differential learning rates
    optimizer_config:
      type: "adamw"
      adamw_params: {lr: 4e-5, weight_decay: 1e-2, betas: [0.9, 0.95]}
      differential_lr: {enable: true, backbone_lr_ratio: 0.1, classifier_lr_ratio: 1.0}
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼šé¢„çƒ­ + ä½™å¼¦é€€ç«
    scheduler_config:
      type: "cosine_with_warmup"
      cosine_params:
        T_0: 20
        T_mult: 1
        eta_min: 1e-7
    
    # è¯„ä¼°æŒ‡æ ‡
    metrics_config:
      primary_metric: "f1"
      metrics: ["accuracy", "precision", "recall", "f1", "auroc"]
      threshold: 0.5

# === æ•°æ®é…ç½® ===
# å®šä¹‰æ•°æ®å¤„ç†ç®¡é“
data:
  target: lightning_landslide.src.data.MultiModalDataModule
  params:
    # æ•°æ®è·¯å¾„
    train_data_dir: "dataset/train_data"
    test_data_dir: "dataset/test_data"
    train_csv: "dataset/Train.csv"
    test_csv: "dataset/Test.csv"

    # === é€šé“é…ç½® ===
    # å®šä¹‰å¤šæ¨¡æ€æ•°æ®çš„é€šé“ä½¿ç”¨ç­–ç•¥
    channel_config:
      channel_groups:
        optical: [0, 1, 2, 3]          # R, G, B, NIR - å…‰å­¦é¥æ„Ÿæ•°æ®
        sar_amplitude: [4, 5, 8, 9]    # SARå¹…åº¦å›¾ - é›·è¾¾æ•°æ®çš„å¼ºåº¦ä¿¡æ¯
        sar_difference: [6, 7, 10, 11] # SARå·®å€¼å›¾ - æ—¶é—´å˜åŒ–ä¿¡æ¯  
        derived: ["ndvi"]              # æ´¾ç”ŸæŒ‡æ ‡ - è®¡ç®—å¾—å‡ºçš„æ¤è¢«æŒ‡æ•°

      # === ä½¿ç”¨æ¨¡å¼å®šä¹‰ - ä¸ºä¸åŒçš„å®éªŒæä¾›é¢„è®¾çš„é€šé“ç»„åˆ ===
      usage_modes:
        # optical_only:
        #   groups: ["optical", "derived"]
        #   description: "ä»…ä½¿ç”¨å…‰å­¦æ•°æ®ï¼Œé€‚åˆåŸºçº¿å®éªŒ"
        
        full_multimodal:
          groups: ["optical", "derived", "sar_amplitude", "sar_difference"]  
          description: "ä½¿ç”¨å…¨éƒ¨æ¨¡æ€ï¼Œé€‚åˆæœ€ç»ˆæ¨¡å‹"
        
        # sar_focused:
        #   groups: ["sar_amplitude", "sar_difference"]
        #   description: "ä¸“æ³¨SARæ•°æ®ï¼Œç”¨äºæ¶ˆèå®éªŒ"

    # é€šé“é…ç½®ï¼šä»…ä½¿ç”¨å…‰å­¦æ•°æ®
    active_mode: "full_multimodal"
    
    # æ•°æ®åŠ è½½é…ç½®
    batch_size: 32
    num_workers: 8
    pin_memory: true
    
    # æ•°æ®åˆ†å‰²é…ç½®
    val_split: 0.2
    stratify: true
    shuffle_train: true

    # === æ•°æ®é¢„å¤„ç†é…ç½® ===
    preprocessing:
      # æ ‡å‡†åŒ–å‚æ•° - åŸºäºæ‚¨çš„æ•°æ®ç»Ÿè®¡è®¡ç®—å¾—å‡º
      normalization:
        # 12ä¸ªåŸå§‹é€šé“çš„å‡å€¼å’Œæ ‡å‡†å·®
        means: [1849.282, 1953.906, 1896.493, 3291.47, -9.624, -17.110, 
                -0.699, -0.483, -10.671, -18.442, 0.248, -0.234]
        stds: [1414.462, 1338.292, 1342.528, 1448.362, 7.904, 9.245, 
               4.062, 4.283, 6.333, 8.691, 2.777, 3.932]
      
      # NDVIè®¡ç®—é…ç½®
      ndvi_computation:
        red_channel_idx: 0
        nir_channel_idx: 3
        epsilon: 1e-8
        clip_range: [-1, 1]

    # æ•°æ®å¢å¼ºé…ç½®
    augmentation:
      train:
        resize: 256
        # å‡ ä½•å¢å¼º
        geometric:
          random_flip: true
          h_flip_prob: 0.5
          v_flip_prob: 0.5
          random_rotation: true
          rotation_prob: 0.3
          rotation_degrees: [-10, 10]
        # å…‰è°±å¢å¼º
        spectral:
          spectral_noise: true
          noise_std: 0.005
          noise_prob: 0.3
      val: {resize: 256}
      test: {resize: 256}

# === åˆ†æ­¥ä¸»åŠ¨å­¦ä¹ é…ç½® ===
# æ–°å¢ï¼šä¸»åŠ¨å­¦ä¹ ç‰¹å®šé…ç½®
active_pseudo_learning:
  # åŸºæœ¬å‚æ•°
  max_iterations: 5                     # æœ€å¤§è¿­ä»£æ¬¡æ•°
  annotation_budget: 50                 # æ¯è½®æ ‡æ³¨é¢„ç®—
  
  # ä¸ç¡®å®šæ€§ä¼°è®¡é…ç½®
  uncertainty_estimation:
    method: "mc_dropout"                # æ–¹æ³•ï¼šmc_dropout
    params:
      n_forward_passes: 5              # MC Dropoutå‰å‘ä¼ æ’­æ¬¡æ•°
      use_temperature_scaling: false    # æ˜¯å¦ä½¿ç”¨æ¸©åº¦ç¼©æ”¾
      dropout_rate: 0.2                 # ä¸æ¨¡å‹é…ç½®ä¸­çš„dropout_rateä¸€è‡´
  
  # ä¼ªæ ‡ç­¾ç”Ÿæˆé…ç½®
  pseudo_labeling:
    confidence_threshold: 0.85          # ä¼ªæ ‡ç­¾ç½®ä¿¡åº¦é˜ˆå€¼
    uncertainty_threshold: 0.1          # ä¸ç¡®å®šæ€§é˜ˆå€¼
    use_adaptive_threshold: false       # æ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
    use_class_balance: true             # æ˜¯å¦è€ƒè™‘ç±»åˆ«å¹³è¡¡
    
    # é«˜çº§é…ç½®
    quality_weights:
      confidence_weight: 0.6            # ç½®ä¿¡åº¦æƒé‡
      uncertainty_weight: 0.3           # ä¸ç¡®å®šæ€§æƒé‡
      consistency_weight: 0.1           # ä¸€è‡´æ€§æƒé‡
  
  # ä¸»åŠ¨å­¦ä¹ é€‰æ‹©ç­–ç•¥
  active_learning:
    budget_per_iteration: 50            # æ¯è½®é€‰æ‹©é¢„ç®—
    strategies:
      uncertainty: 0.6                  # ä¸ç¡®å®šæ€§é‡‡æ ·æƒé‡
      diversity: 0.3                    # å¤šæ ·æ€§é‡‡æ ·æƒé‡
      cluster_based: 0.1                # èšç±»é‡‡æ ·æƒé‡
    
    # å¤šæ ·æ€§é…ç½®
    diversity_params:
      distance_metric: "cosine"         # è·ç¦»åº¦é‡
      n_clusters: 10                    # èšç±»æ•°é‡
      feature_layer: "backbone"         # ç‰¹å¾æå–å±‚
    
    # èšç±»é…ç½®
    cluster_params:
      cluster_method: "kmeans"          # èšç±»æ–¹æ³•
      n_init: 10                        # K-meansåˆå§‹åŒ–æ¬¡æ•°

# === è®­ç»ƒå™¨é…ç½® ===
# ä¸»è¦ç”¨äºé‡è®­ç»ƒæ­¥éª¤
trainer:
  target: pytorch_lightning.Trainer
  params:
    max_epochs: 100
    accelerator: "gpu"         # ä½¿ç”¨GPU
    devices: 1                 # ä½¿ç”¨1ä¸ªGPU
    precision: "32-true"       # ä½¿ç”¨32ä½ç²¾åº¦ï¼Œä¸ä½¿ç”¨æ··åˆç²¾åº¦
    
    # éªŒè¯é…ç½®
    val_check_interval: 1.0     # æ¯ä¸ªepochåéªŒè¯ï¼Œæ¯ä¸ªepochéªŒè¯ä¸€æ¬¡
    check_val_every_n_epoch: 1  # æ¯ä¸ªepochéªŒè¯ä¸€æ¬¡
    
    # æ¢¯åº¦é…ç½®
    gradient_clip_val: 1.0      # æ¢¯åº¦è£å‰ª
    accumulate_grad_batches: 1  # æ¢¯åº¦ç´¯ç§¯
    
    # æ€§èƒ½ä¼˜åŒ–
    enable_progress_bar: true   # æ˜¾ç¤ºè¿›åº¦æ¡
    enable_model_summary: true  # æ˜¾ç¤ºæ¨¡å‹æ‘˜è¦
    deterministic: false        # ä¸ºäº†æ€§èƒ½ï¼Œä¸è¦æ±‚å®Œå…¨ç¡®å®šæ€§

# === å›è°ƒå‡½æ•°é…ç½® ===
# å®šä¹‰è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç›‘æ§ã€ä¿å­˜å’Œæ§åˆ¶ç­–ç•¥
callbacks:
  # æ¨¡å‹æ£€æŸ¥ç‚¹
  model_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: "lightning_landslide/exp/${experiment_name}/checkpoints"  # âœ… ä½¿ç”¨å®éªŒåç§°è·¯å¾„
      filename: "best-{epoch:02d}-{val_f1:.4f}"
      monitor: "val_f1"         # ç›‘æ§æŒ‡æ ‡
      mode: "max"               # æœ€å¤§å€¼
      save_top_k: 1              # ä¿å­˜æœ€å¥½çš„1ä¸ªæ¨¡å‹
      save_last: true            # ä¿å­˜æœ€åä¸€ä¸ªæ¨¡å‹
      verbose: true              # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
  
  # æ—©åœï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ
  early_stopping:
    target: pytorch_lightning.callbacks.EarlyStopping
    params:
      monitor: "val_f1"         # ç›‘æ§æŒ‡æ ‡
      mode: "max"               # æœ€å¤§å€¼
      patience: 20              # æ—©åœæ¬¡æ•°
      verbose: true              # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
      strict: false              # éä¸¥æ ¼æ¨¡å¼ï¼Œå…è®¸æŒ‡æ ‡å¶å°”ä¸å­˜åœ¨
      min_delta: 0.001
  
  # å­¦ä¹ ç‡ç›‘æ§ï¼šè¿½è¸ªå­¦ä¹ ç‡å˜åŒ–
  lr_monitor:
    target: pytorch_lightning.callbacks.LearningRateMonitor
    params:
      logging_interval: "epoch"  # è®°å½•å­¦ä¹ ç‡å˜åŒ–
      log_momentum: false        # ä¸è®°å½•åŠ¨é‡
  
  # è‡ªå®šä¹‰å›è°ƒï¼šæ¨¡å‹ç»Ÿè®¡å’Œå¯è§†åŒ–
  metrics_logger:
    target: lightning_landslide.src.utils.metrics.MetricsLogger
    params:
      summary_interval: 10  # æ¯10ä¸ªepochæ‰“å°è¯¦ç»†æ€»ç»“
      save_history: true   # ä¿å­˜å®Œæ•´å†å²

# === æ—¥å¿—è®°å½•å™¨é…ç½®ï¼ˆä¿®å¤ç‰ˆï¼‰===
# ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨å®éªŒåç§°ä½œä¸ºç›®å½•å
logger:
  target: pytorch_lightning.loggers.TensorBoardLogger
  params:
    save_dir: "lightning_landslide/exp"           # âœ… åŸºç¡€ç›®å½•
    name: "${experiment_name}"                    # âœ… ä½¿ç”¨å®éªŒåç§°ä½œä¸ºå­ç›®å½•å
    version: ""                                   # âœ… ä¸ä½¿ç”¨versionç¼–å·
    log_graph: false
    default_hp_metric: false

# === è¾“å‡ºç›®å½•é…ç½® ===
# å®šä¹‰æ‰€æœ‰è¾“å‡ºæ–‡ä»¶çš„ä¿å­˜ä½ç½®
outputs:
  base_dir: "lightning_landslide/exp"
  experiment_dir: "lightning_landslide/exp/${experiment_name}"
  checkpoints_dir: "${outputs.experiment_dir}/checkpoints"
  logs_dir: "${outputs.experiment_dir}/logs"
  predictions_dir: "${outputs.experiment_dir}/predictions"
  active_learning_dir: "${outputs.experiment_dir}/active_learning"  # ä¸»åŠ¨å­¦ä¹ ä¸“ç”¨ç›®å½•
  
  # ä¸»åŠ¨å­¦ä¹ ä¿å­˜è®¾ç½®
  save_config: true
  save_predictions: true
  save_model_summary: true
  save_uncertainty_scores: true        # ä¿å­˜ä¸ç¡®å®šæ€§åˆ†æ•°
  save_selection_history: true         # ä¿å­˜é€‰æ‹©å†å²
  save_annotation_results: true        # ä¿å­˜æ ‡æ³¨ç»“æœ

# === è®¡ç®—é…ç½® ===
compute:
  # GPUé…ç½®
  gpu_ids: [0]                  # ä½¿ç”¨çš„GPUåˆ—è¡¨
  mixed_precision: false        # ä¸å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
  
  # å†…å­˜ä¼˜åŒ–
  find_unused_parameters: false # DDPæ—¶æ˜¯å¦æŸ¥æ‰¾æœªä½¿ç”¨å‚æ•°
  sync_batchnorm: true          # æ˜¯å¦åŒæ­¥æ‰¹æ ‡å‡†åŒ–

  # æ€§èƒ½ç›‘æ§
  profiler: null                # æ€§èƒ½åˆ†æå™¨ï¼šnull/simple/advanced/pytorch
  
# === å®éªŒç‰¹å®šé…ç½® ===
# è¿™ä¸ªå®éªŒçš„ç‰¹æ®Šè®¾ç½®å’Œè¶…å‚æ•°
experiment_config:
  # æ•°æ®å¹³è¡¡ç­–ç•¥
  class_balance_strategy: "focal_loss"  # focal_loss/weighted_sampling/cost_sensitive
  
  # è¯„ä¼°ç­–ç•¥
  evaluation_strategy:
    use_tta: true
    tta_augmentations: 4
    confidence_threshold: 0.5
  
  reporting:
    generate_confusion_matrix: true
    generate_roc_curve: true
    generate_precision_recall_curve: true
    save_predictions: true
    save_model_summary: true
